\section{Linear types}\label{sec:linear-types}
Type systems in programming languages allow us to offload the burden of verifying semantic
properties of programs by purely from their syntax. Most popular type systems
such as in C or C++ allow for verifying the property that, given a function
of type \texttt{\input{listings/example-c-proving.tex}}, if the input has a particular
layout in memory, then the output memory will also be of particular shape.
They don't provide direct support
for verifying high-level correctness or complexity properties.
Functional programming languages with strong type systems exist, allowing to
verify quite useful correctness properties --- one example is the language Haskell. Going yet
stronger, Lean and Rocq are at the same time programming languages and proof assistants, i.e.\ 
their type systems allow to prove very abstract mathematical properties of the functions they define.
However, none of the mainstream languages allow to enforce useful computational complexity properties
of programs.

One of the properties that is notoriously difficult to enforce
is preventing data from being copied\footnote{We can delete the copy constructor in C++, but it's of course bypassable.}
or discarded without being used\footnote{Yes, we can use a linter to detect unused variables, but
that again doesn't enforce anything.}.
We will also refer to variables being non-copyable as \emph{affine} and reserve the term \emph{linear} for variables
that must be used \emph{exactly} once, i.e.\ neither duplicated nor discarded. The affinity requirement
can be enforced by the variable going out-of-scope after it was used anywhere.
Affine variables are important in logspace computations in which such copying large enough data
is simply not implementable. Linear variables, on the other hand, are reminiscent of
the requirement of class instance construction operation being always matched by a corresponding destruction operation.
We will see an example of affinity exhibited by linear types in Haskell in~\autoref{lst:haskell-linear-example}.
We have already been studying similar concepts for decades in the field of proof theory, where a proof system
may or may not have the so-called \emph{structural} rules: weakening, contraction and exchange.
Proof systems that lack one of these rules are studied in the field of linear logic,
introduced in~\cite{GIRARD19871} with a clear intent to be used in computer science.
The semantics of linear logic has a natural interpretation of logical variables modeling some \emph{resources}.
The concepts from linear logic have been used almost directly for studying
\emph{linear type systems},
that in (typically functional) programming languages, can control the property of cloning and discarding data.

Some of the mainstream programming languages have support for linear types. Haskell (GHC >= 9.0.1) supports
a limited version of linear types. In Rust, linear reasoning can be performed with the mechanism of ownership and borrowing.
Going less mainstream, Idris 2, F* and Q* (which is a quantum programming language)
also support different versions of linear types.


\begin{rawlisting}
\input{listings/haskell-linear-example.tex}
\caption{Example of linear types in Haskell}\label{lst:haskell-linear-example}
\end{rawlisting}




As it turns out, this level of control is also enough to limit the computational complexity of functions implementable
in the language. Example in~\cite{Schopp07},~\cite{DaLagoSchopp10},~\cite{Leivant93},~\cite{10.1007/11874683_40}~\cite{mazza:LIPIcs.CSL.2015.24}.
% In~\cite{4276584}, Stratified Bounded Affine Logic is introduced to capture \complexity{FL} computation.
\begin{remark}
Please note that controlling the computational complexity of programs through the complexity of their specification
was discussed by us in~\autoref{chap:descriptive-complexity}. There, however, the control went through model theory.
Here, the limitations are entirely in the world of proof theory, which is much better connected to
computation than model theory.
\end{remark}





At the same time, the depth of connections between logic, type systems and complexity theory is astonishing
and already well-explored in the literature, e.g.\ \cite{TODO}. We will not repeat these definitions here.
The formal bridge between the theories of linear types and the different kinds of linear logics is the Curry--Howard correspondence,
also known as ``propositions as types'', or ``proofs as programs''.


A good introduction to it is the book by S\o{}rensen and Urzyczyn:~\cite{10.5555/1197021}.


We can think of Curry howard ICC style as programming in ML~\cite{chrzaszcz_et_al:LIPIcs.CSL.2012.198}.


A good introduction to the linear logic / curry-howard approach to implicit complexity is~\cite{BenedettiPhd}.

\subsection{IntML}\label{sec:intml}
In 2013, Dal Lago and Sch\"opp introduced \textbf{IntML}, a functional programming language with a linear type
 system that characterizes \complexity{FLOGSPACE} \cite{DALLAGO2016150}. This marked a significant milestone for 
 Implicit Computational Complexity (ICC). An implementation of IntML is available on
  GitHub\footnote{\url{https://github.com/uelis/IntML}. Following my private communication with the authors, 
  a permissive license was added to the repository, as it was not included originally.}, and to the best of
   my knowledge it remains the only language within the linear-logic branch of ICC that has both a working 
   implementation and some potential for (academic) practical use.






% Programming languages often use type systems to aid the programmer in mechanical checking
% of the most basic properties of programs. For some programmers, \emph{typing} their programs
% is not helpful and they prefer to use languages such as Python that don't
% enforce the types statically. For others, the burden of \emph{debugging} their programs after
% they ceased to actually do what we thought they should is so high, that they turn to \emph{statically}
% typed languages. Languages such as C and C++ offer type systems with very little expressive power,
% in the means of properties of functions we can verify. They don't allow us to e.g\ declare
% that a function, given $x: \mathbb{N}$, will return the prime factors of $x$ in such a way that
% this specification will be enforcable by the compiler.
% A prominent discovery in computer science was that if we take lambda calculus as the computational model
% underlying a programming language, we can limit what can and cannot be written as a program by designing
% an appropriate \emph{type system}. Some of the modern languages, mostly from the ML family (Standard ML,
% OCaml, Haskell), have type systems that at the same time are strong enough to actually reduce the number of
% errors in the code and fast enough to be useful on a daily basis.