\chapter{Linear types}\label{chap:linear-types}

% \subsection{How can STLC be HOL, if System F is weaker than second order logic?}
% % system f is second-order propositional, which is different to second-order
% % https://mathoverflow.net/questions/344446/proof-theory-and-subsystems-of-second-order-arithmetic-in-particular-the-revers
% \subsection{Can STLC compute less functions (after type erasue) than System F?}

% \subsection{Curry-Howard correspondence}

\section{Implicit Computational Complexity: linear logic approach}\label{sec:icc-linear}
\url{https://github.com/uelis/IntML}
\todo[inline]{Here, just show that Ugo dal Lago created IntML.
Say roughly what linear types are, don't get into details.}

% This chapter introduces the minimal fragment of linear logic and its term assignment needed later. The purpose is to contrast ordinary (intuitionistic) derivations with linear derivations where duplication and discarding of assumptions are controlled. Only the connectives $\multimap$ and ${!}$ are used, together with the falsity constant $\bot$ for completeness. No multiplicative products or additive connectives are introduced.

% \section{Structural rules}
% \label{sec:linear-structural}

% In intuitionistic propositional reasoning and in the simply typed $\lambda$-calculus, contexts admit \emph{contraction} (assumptions may be duplicated) and \emph{weakening} (assumptions may be ignored). Linear logic removes these two principles from the default context and admits them only through an explicit modality ${!}$.

% \begin{enumerate}
%   \item \textit{No weakening in the linear context:} every linear assumption must be used.
%   \item \textit{No contraction in the linear context:} linear assumptions cannot be duplicated.
%   \item \textit{Exchange:} reordering assumptions is permitted.
% \end{enumerate}

% \section{Propositional linear logic}
% \label{sec:lin-logic}

% \paragraph{Atomic formulas.}
% Fix a countable set $\mathcal{P}=\{P,Q,R,\dots\}$ of propositional variables. The set of atomic formulas is $\mathcal{A}_0 := \mathcal{P} \cup \{\bot\}$, where $\bot$ is falsity.

% \paragraph{Formulas.}
% \[
% A ::= A_0 \mid (A \multimap A) \mid {!}A \qquad (A_0 \in \mathcal{A}_0).
% \]

% \paragraph{Contexts and judgments.}
% Judgments have the form $\Gamma \,;\, \Delta \vdash A$, where $\Gamma$ (unrestricted context) contains formulas of the form ${!}B$, and $\Delta$ (linear context) contains linear formulas. In rules below, $\Delta_1 \uplus \Delta_2$ denotes a disjoint split of the multiset $\Delta$.

% \paragraph{Rules.}
% Identity:
% \[
% \infer[\mathrm{id}]
%       {\Gamma \,;\, A \vdash A}{}
% \qquad
% \infer[\mathrm{id}!]
%       {\Gamma,{!}A \,;\, \cdot \vdash A}{}
% \]

% Linear implication:
% \[
% \infer[\multimap\mathrm{I}]
%       {\Gamma \,;\, \Delta \vdash A \multimap B}
%       {\Gamma \,;\, \Delta, A \vdash B}
% \qquad
% \infer[\multimap\mathrm{E}]
%       {\Gamma \,;\, \Delta_1 \uplus \Delta_2 \vdash B}
%       {\Gamma \,;\, \Delta_1 \vdash A \multimap B
%        \quad
%        \Gamma \,;\, \Delta_2 \vdash A}
% \]

% Exponentials (${!}$):
% \[
% \begin{gathered}
% \infer[\mathrm{dereliction}]
%       {\Gamma \,;\, \Delta, {!}A \vdash A}{} \\[4pt]
% \infer[\mathrm{weak}!]
%       {\Gamma,{!}A \,;\, \Delta \vdash C}
%       {\Gamma \,;\, \Delta \vdash C} \\[4pt]
% \infer[\mathrm{contr}!]
%       {\Gamma,{!}A \,;\, \Delta \vdash C}
%       {\Gamma,{!}A,{!}A \,;\, \Delta \vdash C}
% \end{gathered}
% \]
% \[
% \infer[\mathrm{promotion}]
%       {\Gamma \,;\, \Delta \vdash {!}A}
%       {\Gamma \,;\, \cdot \vdash A}
% \]

% The unrestricted context $\Gamma$ admits weakening and contraction via the explicit rules above. The linear context $\Delta$ admits neither.

% \section{Linear \texorpdfstring{$\lambda$}{lambda}-calculus (term assignment)}
% \label{sec:lin-lambda}

% \paragraph{Atomic types.}
% Fix a countable set $\mathcal{T}_0=\{\alpha,\beta,\gamma,\dots\}$ of base types and include $\bot$. Atomic types are $\mathcal{U}_0:=\mathcal{T}_0 \cup \{\bot\}$.

% \paragraph{Types and terms.}
% \[
% \tau ::= U_0 \mid (\tau \multimap \tau) \mid {!}\tau
% \qquad (U_0 \in \mathcal{U}_0).
% \]
% \[
% t ::= x \mid \lambda x{:}\tau.\, t \mid (t\,u) \mid \mathsf{abort}_{\tau}(t).
% \]
% Here $\mathsf{abort}_{\tau}(t)$ is the eliminator for $\bot$.

% \paragraph{Typing.}
% Typing judgments have the form $\Gamma \,;\, \Delta \vdash t : \tau$, where $\Gamma$ records unrestricted variables and $\Delta$ records linear variables.
% \[
% \begin{gathered}
% \infer[\mathrm{var}]
%       {\Gamma \,;\, x{:}\tau \vdash x : \tau}{} \\[4pt]
% \infer[\mathrm{var}!]
%       {\Gamma, x:{!}\tau \,;\, \cdot \vdash x : \tau}{}
% \end{gathered}
% \]
% \[
% \begin{gathered}
% \infer[\multimap\mathrm{I}]
%       {\Gamma \,;\, \Delta \vdash \lambda x{:}\sigma.\, t : \sigma \multimap \rho}
%       {\Gamma \,;\, \Delta, x{:}\sigma \vdash t : \rho} \\[4pt]
% \infer[\multimap\mathrm{E}]
%       {\Gamma \,;\, \Delta_1 \uplus \Delta_2 \vdash t\,u : \rho}
%       {\Gamma \,;\, \Delta_1 \vdash t : \sigma \multimap \rho
%        \quad
%        \Gamma \,;\, \Delta_2 \vdash u : \sigma}
% \end{gathered}
% \]
% \[
% \begin{gathered}
% \infer[\mathrm{dereliction}]
%       {\Gamma \,;\, \Delta, x:{!}\sigma \vdash x : \sigma}{} \\[4pt]
% \infer[\mathrm{promotion}]
%       {\Gamma \,;\, \Delta \vdash t : {!}\sigma}
%       {\Gamma \,;\, \cdot \vdash t : \sigma} \\[4pt]
% \infer[\bot\mathrm{E}]
%       {\Gamma \,;\, \Delta \vdash \mathsf{abort}_{\tau}(t) : \tau}
%       {\Gamma \,;\, \Delta \vdash t : \bot}
% \end{gathered}
% \]

% \paragraph{Evaluation.}
% Evaluation is by $\beta$-reduction, closed under the usual congruence rules:
% \[
% (\lambda x{:}\sigma.\, t)\,u \;\to_\beta\; t[x:=u].
% \]
% No reduction rule is given for $\mathsf{abort}_{\tau}$.

% \section{Curry--Howard identification}
% \label{sec:ch-linear}
% Under the identification of formulas with types and derivations with well-typed terms: $\multimap$ corresponds to the linear function space, and the rules for ${!}$ correspond to the admissibility of duplication and discarding in the unrestricted context. The separation $\Gamma \,;\, \Delta$ enforces that each variable in $\Delta$ is used exactly once.

% \section{Example}
% \label{sec:example-linear}

% \paragraph{Statement.}
% \[
% \vdash\; (A \multimap B) \multimap A \multimap B.
% \]

% \paragraph{Derivation.}
% \[
% \infer[\multimap\mathrm{I}]{\; \vdash (A \multimap B) \multimap A \multimap B \;}{
%   \infer[\multimap\mathrm{I}]{\; A \multimap B \vdash A \multimap B \;}{
%     \infer[\multimap\mathrm{E}]{\; A \multimap B, A \vdash B \;}{
%       \infer[\mathrm{id}]{A \multimap B \vdash A \multimap B}{}
%       &
%       \infer[\mathrm{id}]{A \vdash A}{}
%     }
%   }
% }
% \]

% \paragraph{Program.}
% \[
% \lambda f{:}A \multimap B.\,\lambda a{:}A.\, f\,a \;:\; (A \multimap B) \multimap A \multimap B.
% \]

% \paragraph{Executable instance (Haskell, \texttt{LinearTypes}).}
% \begin{verbatim}
% {-# LANGUAGE LinearTypes #-}
% module Main where

% -- apply : (a %1-> b) %1-> a %1-> b
% apply :: (a %1-> b) %1-> a %1-> b
% apply f a = f a

% idL :: a %1-> a
% idL x = x

% main :: IO ()
% main = print (apply idL (42 :: Int))
% \end{verbatim}

% \section{Implicit computational complexity (orientation)}
% \label{sec:icc-orientation}
% The rules for ${!}$ make duplication and discarding explicit in derivations and in typing. 
% Restrictions on the use of ${!}$ (e.g., stratification) yield bounds on normalization and can 
% characterize complexity classes. One instance is the language \emph{IntML} by Dal Lago and Sch\"opp, 
% designed to capture \textbf{\complexity{FLOGSPACE}} via a linear typing discipline \cite{DALLAGO2016150}.
%  An implementation is available.\footnote{\url{https://github.com/uelis/IntML}.}






% \chapter{Linear types}
% \label{chap:linear-types}

% Linear logic can be thought of not as true facts we can reason upon or deduce,
% but as resources that we can obtain and utilize (sometimes, destructively).


% suppose that we have a web server. clients come to us and ask for a resource of type `b`.
% we don't have it yet, but we have a function `a -> b`, and there is a small chance that
% one client will send an erroneous request, with a valid object of type $a$ in it.
% after this moment, we will just call our function, and send the b obtained to all clients.

% gamma |- alpha, alpha->beta -> gamma|- b.

% now, what if we have a bakery and the erroneous client give us a cake instead of buying it?
% logically, the naive approach would be to 
% we will be able to satisfy one clinet, but not the whole queue. yet, traditionally in logic we
% don't have a way to 


% What if we could encode in the type system that a function can only read an argument once?
% Or that if you call a function A -> B on argument of type A, then you have access to an element
% of type B, but lose the access to the original argument A (goes out of scope)?
% Consider such a semantics of computer program:
% - (contraction) once you use a variable, it goes out of scope
% - (weakening) function is incorrect if at the end of it, some variable is still in scope (was unused)

% This allows us to reason about resource usage in programs.

% This idea is studied by the field of linear type systems.


% A popular way to think of typed programs is to
% think of an object of type $a -> b$ as a method to 
% transform objects of type a to objects of type b.
% so, if you obtain something of type $a$ (so, the type a is nonempty),
% and something of type $a -> b$, then you can also obtain something of type $b$.


% \section{Linear logic}
% % perhaps take intro from this: https://theses.hal.science/tel-01123737v1/file/2015ENSL0981.pdf

% Linear type systems are fully inspired by substructural logics.
% They consider changing contraction and weakening rule, but keep exchange rule.

% The formal bridge between the theories of linear types and the different kinds of linear logics is the Curry--Howard correspondence
% (also known as propositions as types, or proofs as programs).
% Extensive literature exists in this area, also known as the Curry--Howard correspondence. A good introduction to it is a book by S\o{}rensen and Urzyczyn: [@10.5555/1197021].

% The resource interpretation is also there.

% \section{Linear types and resources}

% In intuitionistic logic and the simply typed $\lambda$-calculus, assumptions in the context $\Gamma$ can be freely duplicated (contraction) or ignored (weakening). This corresponds to programs that can copy or discard variables arbitrarily.

% \textbf{Linear logic}, introduced by Girard, restricts these structural rules. In the corresponding $\lambda$-calculus, each variable must be used \emph{exactly once}. This leads to \textbf{linear types}, where values are treated as \emph{resources}:
% \begin{enumerate}[nosep]
%   \item A value must be consumed once (no weakening).
%   \item A value cannot be duplicated (no contraction).
%   \item The order of usage does not matter (exchange is allowed).
% \end{enumerate}

% Thus, linear types provide a fine-grained way to model computation where resources (such as memory cells, channels, or tokens) cannot be copied or discarded at will. This perspective opens the door to implicit control of computational complexity, since unrestricted duplication of resources is closely related to uncontrolled growth in computation.

% \section{Modern results in Implicit Computational Complexity}


% Bang and paragraph are parts of lambda term syntax. The theorem then is that such a term,
% ignoring types, normalizes in polynomial number of beta steps?


% In 2013, Dal Lago and Sch\"opp introduced \textbf{IntML}, a functional programming language with a linear type system that characterizes \complexity{FLOGSPACE} \cite{DALLAGO2016150}. This marked a significant milestone for Implicit Computational Complexity (ICC). An implementation of IntML is available on GitHub\footnote{\url{https://github.com/uelis/IntML}. Following my private communication with the authors, a permissive license was added to the repository, as it was not included originally.}, and to the best of my knowledge it remains the only language within the linear-logic branch of ICC that has both a working implementation and some potential for (academic) practical use.

% Despite this achievement, IntML's complex typing rules make it difficult to translate most standard imperative algorithms into the language without substantial modification. While, in principle, the language could serve as a platform for reimplementing well-known algorithms within this new paradigm, the steep learning curve creates a significant barrier to adoption. As a result, it is unlikely to become a convenient tool for algorithm designers.

% For these reasons, we decided not to pursue IntML further and not to focus on linear type systems in this work. Instead, we turn to another language discussed in Section~\autoref{chap:icc-recursion-theory}.

% \section{Support for linear types in mainstream programming languages}
% Haskell has some. Rust also. Idris 2 has some. F*, Q*. quantum programming uses that a lot!





% \chapter[Propositions as types]{Propositions as types, proofs as programs: the Curry--Howard correspondence}
% \label{chap:curry-howard}

% The aim of this thesis is to reason about computation and its cost on standard machines. To do so, we will fix a minimal logical and computational core that is sufficient to state and track the shape of computations without introducing additional connectives or control features. In this chapter we present the implicational fragment of intuitionistic logic and the simply typed lambda calculus with only function types. We use these and nothing more.

% \section{Computation and stepwise transformation}
% A computation proceeds by a sequence of discrete steps that transform state. On a Turing machine, this discreteness is explicit in the transition function; on conventional hardware it is enforced by the processor clock; in functional languages it is captured by stepwise term rewriting. Counting such steps yields a cost measure employed later in the thesis. No additional effects or control features are used in this chapter.



% \section{Implicational propositional calculus}
% \label{sec:ipc}

% \paragraph{Language.}
% Fix a countable set $\mathcal{P}=\{P,Q,R,\dots\}$ of propositional variables (atomic formulas). Formulas are generated by
% \[
% A ::= \bot \mid P \mid (A \to A) \qquad (P \in \mathcal{P}).
% \]
% Negation is an abbreviation $\neg A := A \to \bot$.

% \paragraph{Hilbert-style calculus.}
% A derivation is a finite sequence of formulas. The system consists of the following axiom schemata and the single inference rule \emph{modus ponens}:
% \[
% \begin{array}{ll}
% \text{(I1)} & A \to (B \to A), \\[2pt]
% \text{(I2)} & \bigl(A \to (B \to C)\bigr) \to \bigl((A \to B) \to (A \to C)\bigr), \\[2pt]
% \text{(EFQ)} & \bot \to A, \\[6pt]
% \multicolumn{2}{l}{\infer[\mathrm{MP}]{B}{A \to B \quad A}.}
% \end{array}
% \]

% \paragraph{Derivability.}
% Let $\Gamma$ be a finite set (or list) of formulas. A formula $C$ is \emph{derivable from $\Gamma$}, written $\Gamma \vdash C$, if there exists a finite sequence $A_1,\dots,A_n$ with $A_n=C$ and, for each $i\le n$, one of the following holds: (i) $A_i$ is an instance of (I1), (I2), or (EFQ); (ii) $A_i \in \Gamma$; (iii) there exist $j,k<i$ and a formula $D$ with $A_j = D \to A_i$ and $A_k = D$ (an application of MP). A \emph{theorem} is a formula $C$ such that $\vdash C$.





% \section{Simply typed lambda calculus}
% \label{sec:stlc}

% \paragraph{Atomic types.}
% Fix a countable set $\mathcal{T}_0=\{\alpha,\beta,\gamma,\dots\}$ of base types (atomic types).

% \paragraph{Types and terms.}
% Types are generated by
% \[
% \tau ::= \bot \mid \alpha \mid (\tau \to \tau) \qquad (\alpha \in \mathcal{T}_0).
% \]
% Terms are
% \[
% t ::= x \mid \lambda x{:}\tau.\, t \mid (t\,u) \mid \mathsf{abort}_{\tau}(t).
% \]
% Here $\mathsf{abort}_{\tau}(t)$ is the eliminator for the empty type $\bot$.

% \paragraph{Typing.}
% Typing judgments have the form $\Gamma \vdash t : \tau$, where $\Gamma$ maps variables to types. The rules are:
% \[
% \infer{\Gamma, x{:}\tau \vdash x : \tau}{}
% \qquad
% \infer{\Gamma \vdash \lambda x{:}\tau.\, t : \tau \to \sigma}{\Gamma, x{:}\tau \vdash t : \sigma}
% \qquad
% \infer{\Gamma \vdash t\,u : \sigma}{\Gamma \vdash t : \tau \to \sigma \quad \Gamma \vdash u : \tau}
% \]
% \[
% \infer{\Gamma \vdash \mathsf{abort}_{\tau}(t) : \tau}{\Gamma \vdash t : \bot}
% \]

% \paragraph{Evaluation.}
% Evaluation is by $\beta$-reduction, closed under the usual congruence rules:
% \[
% (\lambda x{:}\tau.\, t)\,u \;\to_\beta\; t[x:=u].
% \]
% There is no reduction rule for $\mathsf{abort}_{\tau}$.







% \section{Curry--Howard (implicational-only)}
% Under the correspondence:
% \[
% \begin{aligned}
% \text{propositions} &\;\leftrightarrow\; \text{types}, \\
% \text{proofs} &\;\leftrightarrow\; \text{well-typed terms}, \\
% \text{modus ponens / normalization} &\;\leftrightarrow\; \text{application / $\beta$-reduction}.
% \end{aligned}
% \]
% Concretely:
% \begin{enumerate}
%   \item A derivation of $\Gamma \vdash A \to B$ corresponds to a term $\lambda x{:}A.\,t$ with $\Gamma, x{:}A \vdash t : B$.
%   \item A derivation using $\to$-elimination corresponds to application $t\,u$.
% \end{enumerate}
% We will rely only on this fragment.

% \section{Minimal running example}
% We use the tautology
% \[
% A \to (B \to A),
% \]
% which reads: given a value of type $A$, and given a value of type $B$, we can return the original $A$.

% \subsection*{Logical proof (natural deduction)}
% TODO: IS THIS CORRECT? IT LOOOKS LIKE DEDUCTION THEOREM AND NOT IMPLICATION INTRODUCTION
% \[
% \infer[\to\mathrm{I}]{\vdash A \to (B \to A)}{
%   \infer[\to\mathrm{I}]{A \vdash B \to A}{
%     \infer[\mathrm{Ax}]{A, B \vdash A}{}
%   }
% }
% \]
% Reading this bottom-up: assume $A$; under that assumption, assume $B$; by the assumption $A$ we conclude $A$; discharge the $B$-assumption to obtain $B \to A$; discharge the $A$-assumption to obtain $A \to (B \to A)$.

% \subsection*{Program (simply typed lambda calculus) and executable instance}
% The corresponding term is the ``K'' combinator:
% \[
% \lambda a{:}A.\,\lambda b{:}B.\, a \;:\; A \to (B \to A).
% \]
% To run it on a computer, instantiate the atomic types with concrete ones. For example, take $A = \mathsf{int}$ and $B = \mathsf{bool}$ in OCaml:

% \begin{verbatim}
% (* k : int -> bool -> int *)
% let k (a : int) (_b : bool) = a

% let () =
%   let r1 = k 42 true in
%   let r2 = k 7 false in
%   Printf.printf "%d %d\n" r1 r2
% \end{verbatim}

% This program is a direct executable instance of the proof. The application
% \[
% (\lambda a.\,\lambda b.\,a)\ 42\ \mathsf{true} \;\to_\beta\; (\lambda b.\,42)\ \mathsf{true} \;\to_\beta\; 42.
% \]
% No other features are used.

% \section{Summary}
% We fixed the implicational fragment of intuitionistic logic and the simply typed lambda calculus with only function types. Curry--Howard in this fragment identifies proofs with typed lambda terms and proof normalization with $\beta$-reduction. The single example $A \to (B \to A)$ illustrates both sides and compiles to an ordinary program without introducing any additional connectives or control constructs.
