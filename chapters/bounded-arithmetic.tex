\chapter{Bounded arithmetic}\label{chap:bounded-arithmetic}


% TODO: mozna opisac obwody jako arytmetyke: \cite{10.1007/978-1-4612-2566-9_6}
% TODO: zeby zobaczyc jak arytmetyka wpasowuje sie w ICC, prosze zobacz: \cite[Page~19]{DalLagoMartini2006MuTutorial}


In mathematics we typically assume some (pretty strong) foundational axioms we rely on
to prove theorems. If we choose set theory as the foundation (as we usually do), a debatable
concept is whether we should use the axiom of choice or not. More popularly in computer science,
we often want to be explicit about using Kőnig's
lemma\footnote{Note that Kőnig's lemma is a form of countable choice from finite sets.}
and Ramsey's theorem.
If we think of the concept
we introduced in~\autoref{chap:reductions} (i.e.\ writing a program in a language in which calls
of the computation-heavy oracle are explicit), we would often ask ourselves the same question ---
can we write the program without relying on that function, i.e.\ write the program in a lower complexity?
It turns out the similarity is not a coincidence,
and to explore this connection further we need to study \emph{bounded arithmetic},
in particular the theory $\IDeltaZero{}$ and $\compVZero{}$.

\section{Single-sorted logic and \IDeltaZero{}}

\begin{definition}[{\cite[Definition~III.1.1]{Cook_Nguyen_2010}}]
A \emph{theory} over a vocabulary $\mathcal{L}$ is a set $\mathcal{T}$ of $\mathcal{L}$-formulas that is closed
under logical consequence and under universal closure.

Note that we have not defined ``logical consequence''; it depends on the choice of a particular \emph{proof system}
(also called \emph{proof calculus}). We will not define proof systems in detail here.
All results in this chapter assume standard Gentzen-style proof calculus for classical logic,
$\mathrm{LK}$~\cite[Section~II.2.3]{Cook_Nguyen_2010} for single-sorted logic
and $\mathrm{LK}^2$~\cite[Section~IV.4]{Cook_Nguyen_2010} for two-sorted logic.
\end{definition}

\begin{definition}[{\cite[Definition~II.2.3]{Cook_Nguyen_2010}}]
The vocabulary of arithmetic is
\[
\mathcal{L}_A = \langle 0,1,+,\cdot\ ;\ =,\le \rangle .
\]
Here $0,1$ are constant symbols; $+$ and $\cdot$ are binary function symbols; and
$=$ and $\le$ are binary predicate symbols. We will implicitly assume the
standard interpretation of these symbols as the appropriate functions on natural numbers
whenever talking about the semantics of $\mathcal{L}_A$-formulas.
\end{definition}

\begin{definition}[{\cite[Figure~1]{Cook_Nguyen_2010}} Axioms 1-BASIC of Peano arithmetic]
    \[
\begin{array}{@{}l l@{}}
\mathrm{B1.}\; x + 1 \neq 0
&
\mathrm{B5.}\; x \cdot 0 = 0
\\[2pt]
\mathrm{B2.}\; x + 1 = y + 1 \rightarrow x = y
&
\mathrm{B6.}\; x \cdot (y + 1) = (x \cdot y) + x
\\[2pt]
\mathrm{B3.}\; x + 0 = x
&
\mathrm{B7.}\; (x \le y \land y \le x) \rightarrow x = y
\\[2pt]
\mathrm{B4.}\; x + (y + 1) = (x + y) + 1
&
\mathrm{B8.}\; x \le x + y
\\[6pt]
\multicolumn{2}{@{}l@{}}{\text{C.}\; 0 + 1 = 1}
\end{array}
\]
\end{definition}

\begin{definition}[{\cite[Definition~III.1.4]{Cook_Nguyen_2010}} Induction Scheme]
Let $\Phi$ be a set of formulas. The \emph{$\Phi$-IND axioms} are all formulas of the form
\begin{equation}\label{eq:Phi-IND}
\bigl(\varphi(0)\ \land\ \forall x \ldotp (\varphi(x)\rightarrow \varphi(x+1))\bigr)
\ \rightarrow\ \forall z \ldotp \varphi(z),
\end{equation}
where $\varphi$ ranges over formulas in $\Phi$.  Note that $\varphi(x)$ may have free
variables other than~$x$.
\end{definition}

\begin{definition}[{\cite[Definition~III.1.5]{Cook_Nguyen_2010}} Peano Arithmetic]
The theory $\arithPA{}$ has as axioms $\mathrm{B1},\ldots,\mathrm{B8}$, together with the $\Phi$-IND axioms,
where $\Phi$ is the set of all $\mathcal{L}_A$-formulas.

Peano Arithmetic is a powerful theory capable of formalizing the major theorems of
number theory. We define subsystems of $\arithPA{}$ by restricting the induction axioms
to certain sets of formulas. 
\end{definition}

\begin{definition}[{\cite[Definition~III.1.7]{Cook_Nguyen_2010}} \IOPEN{}, \IDeltaZero{}, \ISigmaOne{}]
Let $\mathrm{OPEN}$ be the set of \emph{open} (i.e.\ quantifier-free) formulas, let $\Delta_{0}$
be the set of \emph{bounded} formulas, and let $\Sigma_{1}$ be the set of formulas
of the form $\exists \vec{x} \ldotp \varphi$, where $\varphi$ is bounded and $\vec{x}$ is a
(possibly empty) tuple of variables.  

The theories $\IOPEN{}$, $\IDeltaZero{}$, and $\ISigmaOne{}$ are the subsystems of $\arithPA{}$
obtained by restricting the induction scheme so that $\Phi$ is $\mathrm{OPEN}$, $\Delta_{0}$,
and $\Sigma_{1}$, respectively.
\end{definition}

\begin{lemma}[{\cite[Example~III.1.8]{Cook_Nguyen_2010}}]\label{lemma:props-iopen}
The following formulas (and their universal closures) are theorems of $\IOPEN{}$:
\[
\begin{array}{@{}l l@{}}
\mathrm{O1.}\; (x+y)+z = x+(y+z)
& \text{(Associativity of $+$)} \\[2pt]
\mathrm{O2.}\; x+y = y+x
& \text{(Commutativity of $+$)} \\[2pt]
\mathrm{O3.}\; x\cdot (y+z) = (x\cdot y)+(x\cdot z)
& \text{(Distributive law)} \\[2pt]
\mathrm{O4.}\; (x\cdot y)\cdot z = x\cdot (y\cdot z)
& \text{(Associativity of $\cdot$)} \\[2pt]
\mathrm{O5.}\; x\cdot y = y\cdot x
& \text{(Commutativity of $\cdot$)} \\[2pt]
\mathrm{O6.}\; x+z = y+z \rightarrow x=y
& \text{(Cancellation for $+$)} \\[2pt]
\mathrm{O7.}\; 0 \le x
& \\[2pt]
\mathrm{O8.}\; x \le 0 \rightarrow x=0
& \\[2pt]
\mathrm{O9.}\; x \le x
& \\[2pt]
\mathrm{O10.}\; x \neq x+1
&
\end{array}
\]
\end{lemma}

\begin{lemma}[{\cite[Example~III.1.9]{Cook_Nguyen_2010}}]\label{lemma:props-idelta0}
The following formulas (and their universal closures) are theorems of $\IDeltaZero{}$:
\[
\begin{array}{@{}l l@{}}
\mathrm{D1.}\; x\neq 0 \rightarrow \exists y\le x \ldotp (x=y+1)
& \text{(Predecessor)} \\[2pt]
\mathrm{D2.}\; \exists z \ldotp \bigl(x+z=y \,\lor\, y+z=x\bigr)
& \\[2pt]
\mathrm{D3.}\; x\le y \leftrightarrow \exists z \ldotp (x+z=y)
& \\[2pt]
\mathrm{D4.}\; (x\le y \land y\le z) \rightarrow x\le z
& \text{(Transitivity)} \\[2pt]
\mathrm{D5.}\; x\le y \lor y\le x
& \text{(Total order)} \\[2pt]
\mathrm{D6.}\; x\le y \leftrightarrow x+z \le y+z
& \\[2pt]
\mathrm{D7.}\; x\le y \rightarrow x\cdot z \le y\cdot z
& \\[2pt]
\mathrm{D8.}\; x\le y+1 \leftrightarrow (x\le y \lor x=y+1)
& \text{(Discreteness 1)} \\[2pt]
\mathrm{D9.}\; x<y \leftrightarrow x+1\le y
& \text{(Discreteness 2)} \\[2pt]
\mathrm{D10.}\; x\cdot z = y\cdot z \land z\neq 0 \rightarrow x=y
& \text{(Cancellation for $\cdot$)}
\end{array}
\]
\end{lemma}

Using the above lemmas as building blocks, we can prove quite a few nontrivial theorems.
We will now introduce the core notion of arithmetic --- what does it mean to \emph{define} a function
\emph{in a theory}.


\begin{definition}[{\cite[Definition~III.3.2]{Cook_Nguyen_2010}} Predicates and Functions definable in a Theory]
    Let $\mathcal{T}$ be a theory with vocabulary $\mathcal{L}$, and let $\Phi$ be a set of $\mathcal{L}$-formulas.

\begin{enumerate}
    \item
    a predicate symbol $P(x)\notin \mathcal{L}$ is \emph{$\Phi$-definable in $\mathcal{T}$} if there exists
    an $\mathcal{L}$-formula $\varphi(x)\in\Phi$ such that
\begin{equation}\label{eq:defining-predicate}
P(x)\;\leftrightarrow\;\varphi(x).
\end{equation}

    \item
    a function symbol $f(x)\notin \mathcal{L}$ is \emph{$\Phi$-definable in $\mathcal{T}$} if there exists
    a formula $\varphi(x,y)\in\Phi$ such that
    \begin{equation}\label{eq:unique-existence}
    \mathcal{T} \vdash \forall x \ldotp \exists! y \ldotp \varphi(x,y),
    \end{equation}
    and moreover
    \begin{equation}\label{eq:defining-function}
    y=f(x)\;\leftrightarrow\;\varphi(x,y).
    \end{equation}
\end{enumerate}

    We call \eqref{eq:defining-predicate} a \emph{defining axiom} for $P(x)$ and
    \eqref{eq:defining-function} a \emph{defining axiom} for $f(x)$.
    A symbol is \emph{definable in $\mathcal{T}$} if it is $\Phi$-definable in $\mathcal{T}$ for some $\Phi$.
\end{definition}

\begin{definition}
    We will say that a function is \emph{provably total} in $\mathcal{T}$ iff it
    is $\Sigma_1$-definable in $\mathcal{T}$.
\end{definition}


In~\cite[Section~III.3]{Cook_Nguyen_2010} it is argued that: the functions $\lfloor x/y \rfloor,\;\big \lfloor \sqrt{x} \big \rfloor,
\;\max(0, x - y),\;x\!\!\mod y$ are definable in \IDeltaZero{}; relation $x \mid y$ is definable in \IDeltaZero{},
and, interestingly, the relation $\;\exp(x, y)$ where $\exp(x, y)$ iff $y = 2^x$, is also definable in \IDeltaZero{}.
We don't introduce the specific logical formula defining the relation $\exp(x, y)$, as it is complicated and discussed
in~\cite[Section~III.3]{Cook_Nguyen_2010}.
For a different point of view on these problems, for example\ in~\cite{Jumelet1995} it is shown
that Euler's $\varphi$ function is provably total in \IDeltaZero{}.
However, the limits of expressive power of \IDeltaZero{} are low.

\begin{theorem}[{\cite[Section~III.2]{Cook_Nguyen_2010}}]
\[
\IDeltaZero{} \nvdash \forall x\,\exists y \ldotp \exp(x,y).
\]
Note that $\arithPA{}$ easily proves $\forall  x \ldotp \exists y \ldotp \exp(x,y)$.
\end{theorem}

It is interesting to study the theory $\IDeltaZero{} + \exp$ of $\IDeltaZero{}$ axioms with an additional axiom
stating that the exponential function is definable. As it turns out, this theory enables us to
reason about syntactic constructs such as coding of sets and sequences or context-free
grammar parsing~\cite[Chapter~V,~Section~3]{HajekPudlak1993Metamathematics}
\footnote{Note that they use the name $\mathrm{I}\Sigma_0 + \Omega_1$ instead of $\IDeltaZero{} + \exp$ which is the same.}.

% In~\cite{Buchholz1987ProvablyCF} is is shown that a function to not be provably total in Peano
% arithmetic requires it to be growing too fast. An intuition behind it for the sake of our
% thesis is that functions that are difficult to \emph{prove correct}, but grow slowly (in particular,
% solve decisional problems and only output a boolean value), must have graphs that are not
% easily definable by a logical sentence.

It turns out that a function is $\Sigma_1$-definable in \IDeltaZero{} iff it is in \complexity{FLTH}, functional
version of linear-time hierarchy~\cite[Theorem~III.4.8]{Cook_Nguyen_2010}; for the definition of \complexity{LTH},
refer to~\cite[Section~III.4.1]{Cook_Nguyen_2010} --- as this complexity class is far from what we call ``feasible''
in this work, we don't introduce the details here. Instead, we will now introduce a theory with a good
computational complexity characterization.

\section{Two-sorted logic and \compVZero{}}\label{sec:theory-v0}

\begin{definition}[Axioms of 2-BASIC]\label{def:two-basic}
\[
\begin{array}{@{}l l@{}}
\mathrm{B1.}\; x + 1 \neq 0
&
\mathrm{B7.}\; (x \le y \land y \le x) \rightarrow x = y
\\[2pt]
\mathrm{B2.}\; x + 1 = y + 1 \rightarrow x = y
&
\mathrm{B8.}\; x \le x + y
\\[2pt]
\mathrm{B3.}\; x + 0 = x
&
\mathrm{B9.}\; 0 \le x
\\[2pt]
\mathrm{B4.}\; x + (y + 1) = (x + y) + 1
&
\mathrm{B10.}\; x \le y \lor y \le x
\\[2pt]
\mathrm{B5.}\; x \cdot 0 = 0
&
\mathrm{B11.}\; x \le y \leftrightarrow x < y + 1
\\[2pt]
\mathrm{B6.}\; x \cdot (y + 1) = (x \cdot y) + x
&
\mathrm{B12.}\; x \neq 0 \rightarrow \exists y \le x \ldotp (y + 1 = x)
\\[6pt]
\text{L1.}\; X(y) \rightarrow y < \len{X}
&
\text{L2.}\; y + 1 = \len{X} \rightarrow X(y)
\\[6pt]
\multicolumn{2}{@{}l@{}}{
\text{SE.}\;
\bigl(\len{X} = \len{Y} \land \forall i < \len{X} \ldotp (X(i) \leftrightarrow Y(i))\bigr)
\rightarrow X = Y
}
\end{array}
\]

\end{definition}


\begin{definition}[{\cite[Definition~V.1.2]{Cook_Nguyen_2010}}~Comprehension Axiom]\label{def:comprehension-axiom}
Let $\Phi$ be a set of formulas. The \emph{comprehension axiom scheme for $\Phi$},
denoted $\Phi\text{-}\mathrm{COMP}$, consists of all formulas of the form
\begin{equation}\label{eq:Phi-COMP}
\exists X \le y \ldotp \forall z<y \ldotp \bigl(X(z)\leftrightarrow \varphi(z)\bigr),
\end{equation}
where $\varphi(z)\in\Phi$ and $X$ does not occur free in $\varphi(z)$.
In \eqref{eq:Phi-COMP}, the formula $\varphi(z)$ may have free variables of both
sorts in addition to~$z$.  We are mainly interested in the cases where
$\Phi$ is one of the classes $\Sigma^{B}_{i}$.
\end{definition}

% \begin{notation}\label{not:V.1.2}
% Since \eqref{eq:Phi-COMP} asserts the existence of a finite set $X$ of numbers,
% we will sometimes use standard set-theoretic notation to describe~$X$:
% \begin{equation}\label{eq:set-notation}
% X=\{\,z : z<y \land \varphi(z)\,\}.
% \end{equation}
% \end{notation}

\begin{definition}[$\complexityi{V}{i}$]\label{def:arith-vi}
For $i\ge 0$, the theory $\complexityi{V}{i}$ has vocabulary $\mathcal{L}^{2}_{A}$ and is axiomatized by
2-BASIC together with $\Sigma^{B}_{i}\text{-}\mathrm{COMP}$.

Note that there are no explicit induction axioms for $\complexityi{V}{i}$.
\end{definition}

\begin{theorem}[{\cite[Corollary~V.1.8]{Cook_Nguyen_2010}}]
    Induction is provable in $\complexityi{V}{i}$. Induction for $\Delta_0$ formulas
    is a theorem of \compVZero{}.

    Note that this implies that any theorem $\varphi$ provable in \IDeltaZero{} is also
    provable in \compVZero{}.
\end{theorem}

\begin{theorem}[{\cite[Theorem~V.1.9]{Cook_Nguyen_2010}}]
    For every formula $\varphi$ in the vocabulary $\mathcal{L}_A$ of single-sorted arithmetic,
    if $\compVZero{} \vdash \varphi$, then also $\IDeltaZero{} \vdash \varphi$.
    In other words, \compVZero{} is a \emph{conservative extension} of \IDeltaZero{}.
\end{theorem}

\begin{remark}[{\cite[Section~IV.3]{Cook_Nguyen_2010}} Two-sorted complexity classes]
    When operating in two-sorted logic, we need to redefine what does it mean for a relation to be in a complexity
    class. We will think of numerical arguments $x_i$ of a relation $R(\vec{x}, \vec{X})$ to be passed to
    the deciding Turing machine in unary representation. The string arguments $X_i$ representing finite sets
    of numbers are passed as follows. For a string argument $S$ define $S(i) = 1$ when $i \in S$, 0 otherwise.
    Then the representation $\squarequotes[4]{S}$ of $S$, when the largest member of $S$ is $n$, is defined as
    the following concatenation of bits:
    \[\squarequotes[4]{S} = S(n)S(n - 1) \dots S(1)S(0)\]
    If $S$ is empty then $\squarequotes[4]{S}$ is the empty string.
    Note that $\len{\squarequotes[4]{S}}$ is the same as our
    interpretation of $S$ inside of the theory: $\len{S} = \max(S) + 1$ or $0$ if $S$ is empty.
    
    We will write $\unary{x}$ to denote unary representation of $x$, i.e.\ $1^{x}$
    and $\binary{x}$ to denote binary representation.
    The ultimate input to the Turing machine deciding if $R(\vec{x}, \vec{X})$
    for $\len{\vec{x}}= n, \len{\vec{X}} = N, \len{X_i}=N_i$ is:

    \[
    \unary{n}\;0 \quad \unary{x_1}\;0\;\unary{x_2}\;0\;\dots\;0\;\unary{x_n}\;0\quad\unary{N}
    \; 0 \quad
    \unary{N_1}\;0\;\squarequotes[5][7]{X_1}\;0\;\dots\;0\;\unary{N_N}\;0\;\squarequotes[5][7]{X_N}
    \]


    Note that a purely numerical relation $R(x)$ is in two-sorted polynomial time iff it is computed
    in time $2^{\bigO(n)}$ for $n = \len{\binary{x}}$. The notion of polynomial-time complexity for
    relations with only string arguments $R(\vec{X})$ coincides with our standard intuition.
\end{remark}

\begin{definition}[{\cite[Definition~V.2.1]{Cook_Nguyen_2010}}]
A number function $f$ or string function $F$ is
(\emph{$p$-bounded}) iff there exists a polynomial $p(x,y)$ such that, for all
inputs $x,Y$,
\[
f(x,Y)\ \le\ p\bigl(x,\lvert Y\rvert\bigr)
\qquad\text{or}\qquad
\lvert F(x,Y)\rvert\ \le\ p\bigl(x,\lvert Y\rvert\bigr),
\]
respectively.
\end{definition}


\begin{definition}[{\cite[Definition~V.2.3]{Cook_Nguyen_2010}} Two-sorted functional complexity classes]
Let $\complexity{C}$ be a two-sorted complexity class of relations.  
The corresponding \emph{function class} $\complexity{FC}$ consists of:
\begin{enumerate}
\item all $p$-bounded number functions whose graphs belong to $\complexity{C}$; and
\item all $p$-bounded string functions whose bit graphs belong to $\complexity{C}$.
\end{enumerate}

Note that the classes \complexityi{FAC}{0}, \complexity{FP}, \complexity{FL} are defined in a different way
to what we have used earlier. However, the difference will not matter in this work.
\end{definition}


We don't repeat the definitions of definability in a theory
for the two-sorted case~\cite[Definition~V.4.1]{Cook_Nguyen_2010}.
Recall the definition of $\Sigma_0^B$ formulas~(\autoref{def:SigmaB-PiB-hierarchy}).

\begin{theorem}[{\cite[Corollary~V.5.3]{Cook_Nguyen_2010}}]
    A function is in \FACZero{} iff it is $\Sigma_0^B$-definable in \compVZero{}.
\end{theorem}

\begin{definition}
    The theory \complexity{VC} for a complexity class $\complexity{C}$ has vocabulary $\mathcal{L}^2_A$
    and is axiomatized
    by the axioms of \compVZero{} and one additional axiom depending on the choice of the class $\complexity{C}$.
    The additional axiom can be thought of adding an oracle for a $C$-complete problem to \compVZero{}.
    We skip the (lengthy) technicalities of~\cite[Definition~IX.2.1]{Cook_Nguyen_2010}.
\end{definition}

The theorem below is the central result of our interest in this thesis.

\begin{theorem}[{\cite[Theorem~IX.2.3]{Cook_Nguyen_2010}}]\label{thm:theories-for-classes-from-reductions}
    A function is provably total (in the two-sorted sense) in \complexity{VC} iff it is in \complexity{FC}.
    \begin{remark}
    By adding a single axiom to the theory of \compVZero{}, we can obtain arithmetical hierarchies
    in which the functions that we can define and prove correct are precisely the functions
    from a given complexity class $\complexity{C} = \complexityi{FTC}{0}, \complexityi{FNC}{1}, \complexity{FL}, \complexity{FP}$.
    \end{remark}
\end{theorem}


This way, we obtain theories with very nice properties. They foster certification of complexity
of an algorithm (if the proof of
correctness itself is feasible, see~\autoref{subsec:complexity-alg-proof}).
At the same time, they enable us to prove theorems about the correctness of functions defined.
In~\cite{buss2025logspaceconstructiveprooflsl}, the authors formalize the breakthrough
result \(\complexity{L}=\complexity{SL}\) of~\cite{10.1145/1391289.1391291} inside of the weak
theory of bounded arithmetic~\complexity{VL}.
The complexity of computational content of proofs of the Discrete Jordan Curve Theorem is
examined in~\cite{10.1145/2071368.2071377}.
Expander construction in \complexityi{VNC}{1} was conducted in~\cite{BUSS2020102796}.

Another elegant property of these theories is that the proof of a problem
not being solvable in a given complexity is exactly a proof of independence
of the axiom (corresponding to the problem) from the theory (corresponding to the complexity class).

\begin{theorem}[{\cites[Corollary~7.21]{CookNguyenDraft}[Corollary~VII.2.4]{Cook_Nguyen_2010}}~Independence of \problem{PHP} from \complexityi{VAC}{0}]\label{subsec:vac0-php}
    \[\complexityi{VAC}{0} \nvdash \problem{PHP}\]
\end{theorem}

\subsection{Complexity of algorithm vs complexity of proof}\label{subsec:complexity-alg-proof}
Even when an algorithm is simple, it seems to not always be trivial to ``feasibly'' prove
that it computes the correct result. In our setting, this results in knowing that
a problem can be solved in a complexity class $\complexity{C}$, but not knowing if the corresponding
function can be defined in the theory $\complexity{VC}$ (i.e.\ proved total and correct).
See \cites[Section~IX.7.3]{Cook_Nguyen_2010}[Section~9G.3]{CookNguyenDraft} for
an open problem whether the breakthrough result that binary integer division
is in \complexity{DLOGTIME}-uniform \complexityi{TC}{0}~\cite{HESSE2002695},
means that it can also be proved in the corresponding \complexityi{VTC}{0} theory.
Note that this problem apparently has been solved (affirmatively) in~\cite{Jerabek2022}.


% \begin{definition}[V.4.12] (semantic)
% A string function is said to be \(\Sigma^B_0\)\textit{-definable from a collection} \(L\) of
% two-sorted functions and relations if it is \(p\)-bounded and its bit graph is represented by
% a \(\Sigma^B_0(L)\) formula.  
% Similarly, a number function is \(\Sigma^B_0\)\textit{-definable from} \(L\) if it is \(p\)-bounded
% and its graph is represented by a \(\Sigma^B_0(L)\) formula.
% \medskip
% This \emph{semantic} notion of \(\Sigma^B_0\)-definability should not be confused with \(\Sigma^B_0\)-definability \emph{in a theory} (Definition~V.4.1), which involves provability.  
% The next result connects these two notions.
% \end{definition}

% there are functions whose graphs are in \complexityi{AC}{0} (representable by sigma0b formulas),
% but which do not belong to \complexityi{FAC}{0} (section: proof of witnessing theorem for v0)


\begin{remark}[Bibliography]
The field of bounded arithmetic was initiated by Samuel Buss in his PhD thesis:~\cite{Buss1986}, in which
the theories $\mathrm{S}^1_2$ were introduced to capture reasoning about the polynomial-time hierarchy \complexity{PH}
(not introduced in our thesis).
The first theory designed to capture polynomial time reasoning was the
equational theory $\mathrm{PV}$ (as in: polynomially-verifiable [proofs])
theory from~\cite{10.1145/800116.803756}.
The two-sorted logic language for capturing complexity classes has been introduced by Zambella in~\cite{00d3b11b-ff1c-386f-a929-6943478c4a28}.

Intuitionistic counterparts such as $\mathrm{IS}^1_2$ for $\mathrm{S}^1_2$ and $\mathrm{IPV}$ for $\mathrm{PV}$
have also been studied. However, much less is known about their expressive power.
For the relation of $\mathrm{IS}^1_2$ and $\mathrm{S}^1_2$, please see~\cite{10.1007/3-540-16486-3_91}. In
particular,~\cite[Conjecture~3]{10.1007/3-540-16486-3_91} asks: if $\mathrm{IS}^1_2 \vdash \exists y \ldotp \phi(y, c)$,
then is it true that there is a function $f$, provably correct in $\mathrm{S}^1_2$, such that $f$ \emph{computes}
the Gödel encoding of that $\mathrm{IS}^1_2$ proof? In~\cite[Corollary~8.19]{COOK1993103}, that conjecture
is answered affirmatively. The intuitionistic version $\mathrm{IPV}$ of the theory $\mathrm{PV}$ is discussed
in some detail in~\cite{COOK1993103}.

For a good introduction to \emph{bounded reverse mathematics},
with a very thorough overview of arithmetical theories corresponding to complexity classes below \compFP,
refer to~\cite{Ngu08}.
\end{remark}


\subsection{Programming language \texorpdfstring{$\mathrm{IMP}~(\complexity{PV})$}{IMP (PV)}}\label{sec:bounded-arith-imppv}
An idea for a programming language based on bounded arithmetic was discussed
in~\cite{Li2025FeasibleMathematics}. The language they discuss is $\mathrm{IMP}~(\complexity{PV})$,
based on the equational theory $\complexity{PV}$, which is different from
the theories we have discussed so far. They show how to design an imperative programming language
with Hoare logic as the verification mechanism (i.e.\ as a type system). For this approach to be
implementable in practice, a \emph{formalization} of $\complexity{PV}$ is necessary.
Recall that, as noted in~\autoref{remark-cobham-imppv}, such a programming language would be
very tightly coupled with the function algebra \complexity{Cob}. Given our considerations
from~\autoref{subsec:intensional} about difficulty of writing in such a language,
we would probably need to consider basing the arithmetic
on another characterization before proceeding to implement such a programming language.


\section{Formalization of bounded arithmetic}
We present a feasible way towards formalization of results from bounded arithmetic.
A key benefit of the theories studied in bounded arithmetic, compared with systems from Implicit Computational
Complexity, is that many difficult theorems from mainstream mathematics have already been reproven within them.
That is, 
the expressiveness problems we discussed in~\autoref{subsec:intensional} seem to affect bounded arithmetic
less than the characterizations from ICC\@.


\paragraph{Our contribution}

The showcase files of this thesis are $\texttt{BoundedArithmetic/IOPEN.lean}$
and $\texttt{BoundedArithmetic/IDelta0.lean}$. These files contain the definitions of the \IOPEN{} and \IDeltaZero{}
theories, respectively, and then prove their basic properties that we have introduced in~\autoref{lemma:props-iopen}
and~\autoref{lemma:props-idelta0}. The most important property of these formalizations we aimed to achieve
was for them to be of didactic value, i.e.\ to make it very explicit what axioms we rely on
and how we conduct proofs inside the weak theories. We strived to conduct our proofs
one-to-one as suggested in~\cite{Cook_Nguyen_2010}, the book that we hugely relied on, to make it
clear that we can transfer this style of reasoning from paper to computer.

In the file $\texttt{BoundedArithmetic/Algebra.lean}$ we demonstrate a huge benefit of the
formalization style we have chosen --- the integration of natural numbers as defined in
\IDeltaZero{} with the algebraic structures from the mainstream $\mathtt{Mathlib.Algebra}$.
The effect of such integration is that we will \emph{not} have to re-prove all the
theorems about number theory in bounded arithmetic; after proving the basic properties,
we can derive that the natural numbers modeled by \IDeltaZero{} satisfy the properties of
a semiring; of a commutative monoid; that the addition is right-cancellable, etc.,
``unlocking'' more and more theorems from $\texttt{Mathlib}$.

In the file $\texttt{BoundedArithmetic/AxiomSchemes.lean}$ we present two very short, but very difficult
to design pieces of code: readable definitions of the axiom schemes of induction and comprehension,
and the macros that \emph{reduce} them. Without these macros, this is \emph{very} difficult
to go from the deeply embedded logical formula to a property of the Lean objects we are manipulating.
In our experience, it was expected that it will take one hour to simplify (using tactics such as
$\texttt{conv}, \texttt{simp}, \texttt{rw}$) one instance of an axiom scheme before we can start
proving a theorem with it. The tree of the deeply embedded term even for the simple formulas
we had been studying, easily grew so large that it required \emph{hundreds} of simplification operations
executed in the right order. This part is very brittle and is the main part of the
so-called $\texttt{simp}$-interface of our library, i.e.\ the transformations we can and cannot
use by default in the tactic $\texttt{simp}$; if designed improperly, this tactic can use
a lemma from our library that weakens one of the assumptions and makes the goal unprovable.


In the file $\mathtt{BoundedArithmetic/V0.lean}$ we present\todo{Clean this file, now it's broken}
a way \compVZero{} can be formalized despite the $\mathtt{Mathlib.ModelTheory}$ library for now only supporting
single-sorted logic.\footnote{We have initially started with extending this library to support many sorts,
but this was too much work for our time horizon.}. In the file $\mathtt{BoundedArithmetic/VTC0.lean}$,
we sketch the proof of the two-sorted theory \complexityi{VTC}{0} proving the
pigeonhole principle \problem{PHP} (note that in~\autoref{subsec:vac0-php} we discussed this theorem
not being provable in \compVZero{}), without relying on any complicated deep-embedding for the axiom schemes
(we introduce single instances of them as additional axioms instead). We strived to
make the formalization go one-to-one with the
original~\cites[Corollary~7.21]{CookNguyenDraft}[Corollary~VII.2.4]{Cook_Nguyen_2010}.

In the file \todo{in oracles repo, not in bounded arithmetic}$\mathtt{code-snapshot/roq-fol-proof-mode.v}$ we present a short demonstration
of how does a proof look like in the deeply-embedded logical framework of Coq Library for First-Order Logic.

In the folder $\mathtt{syntax-metaprogramming}$, we present examples of how a simple proof theory
can be deeply embedded in the logic of Lean. 

\paragraph{Comparison: custom interpreter vs existing proof assistants}
To reason about the provability of theorems, we need to formally define the logic considered
and its proof system. Typically, the \emph{meta-language} in which we define logics is the natural language.
Definitions, theorem statements and proofs have to be thoroughly verified by a specialist in the field.
The situation would be similar if we were to implement the interpreter of our programming language in,
say, C++ --- someone would have to review our code to make sure it's coherent and we can't prove false statements
inside of our tool. However, in the past decade, another way became feasible --- we can define
our logics inside of a proof assistant. Then, instead of asking someone to verify our proofs on paper,
have computer verify them for us, utilizing the incredibly strong type-checker of the proof assistant.
We decided to implement all of our code inside of a proof assistant,
because without it we didn't believe anyone would ever dedicate time to verify correctness
of our proofs conducted \emph{inside} of the bounded arithmetic systems (in particular --- that
in no place have we accidentally used reasoning not permitted in the weak theory).

\paragraph{Comparison: available proof assistants}
Modern proof assistants are generally built on very strong underlying logics.
Some systems, such as Metamath, Twelf, LF, or Isabelle, can be used as
frameworks to formalize a variety of object logics and thus to reason
\emph{about} logics themselves. Note we did not mention Isabelle/HOL here, since it is
a particular (and very strong) logic implemented \emph{inside} of Isabelle.
One could instead work in Isabelle/Pure, which only introduces the most basic axioms,
but it requires expertise in Isabelle to ensure that an axiomatization of bounded arithmetic
does not ``cheat'' by exploiting additional axioms of Isabelle/Pure to conduct
reasoning stronger than those of the weak
theory. The other metamathematical frameworks mentioned
above did not seem to offer a clear advantage over the approach we ultimately adopted.
We therefore chose to formalize in two powerful and well-supported systems,
Rocq and Lean, both based on dependent type theory.

\begin{remark}
  The Rocq proof assistant used to be called \emph{Coq}. While the old name is now
  deprecated, existing publications and code written before the name change still
  use the name Coq, and this terminology remains common in the literature.
\end{remark}


\paragraph{Comparison: deep and shallow embeddings}
To formalize a logic in a proof assistant, the most obvious way is to define the proof system from scratch
inside of it, then prove properties about the proof system and design a good UI to make it usable
for actual proving. This approach was chosen by the authors of Coq Library for First-Order
Logic.\footnote{Available here: \url{https://github.com/uds-psl/coq-library-fol/}.}\footnote{Studying this approach was the topic of my research visit at INRIA in September 2025, funded by the ZSM IDUB program.}
Going this way is a tremendous amount of work --- in fact, it cannot be much simpler than essentially
rewriting Rocq from scratch.\todo{Moglbym tutaj pare zdan napisac o tym moim stazu w INRIA.}

However, it is not obvious how to go around this problem. It is impossible to disable the axioms
assumed by the foundations of Rocq and Lean. We certainly wouldn't like to mix $\IDeltaZero{}$
induction with the axioms of dependent type theory and hope for the best. There is one
very elegant approach we can use to formalize a \emph{finitely} axiomatizable theory. We discuss
this in detail in~\autoref{lst:lean-demo}. We also cite two resources for more information on the notion of
deep and shallow embeddings.
Please see~\cite{10.1145/2914770.2837638} for formalization of
type theory inside of type theory;~\cite{prinz_et_al:LIPIcs.ITP.2022.28} for discussion specifically on deep and shallow embeddings.

\paragraph{Comparison: introducing axioms and axioms schemes to the formalization}
Notice how we emphasized that the approach we outline in~\autoref{lst:lean-demo} is elegant for
the theories that are \emph{finitely} axiomatizable. Indeed, it is not obvious how to extend this approach
with an axiom \emph{scheme} --- and we surely need these to study \compVZero{} and \IDeltaZero{}.
One intuitive way to achieve induction \emph{only} for some formulas would be to detect when
a user-provided Lean term such as $\forall x, x \ge x$ is of shape e.g.\ $\Delta_0$. However,
this way we encounter a huge limitation related to what the type $\texttt{Prop}$ is:
any formula written in this way is \emph{just} a logical statement; we have no means
of deconstructing it to the original formula.

This turns out to be a difficult problem to solve, and it seems that the only way of resolving
it is to use a deep embedding of the logical formulas. We made use of the fact that
the independence of Continuum Hypothesis has been characterized a few years ago.\footnote{Lean code available here: \url{https://github.com/flypitch/flypitch}.}
A part of the authors' code ended up in Lean4 Mathlib as the $\texttt{Mathlib.ModelTheory}$ library.
It turned out that we could successfully use this library to formalize the (very complicated)
operations on logical formulas we need to have to manipulate the formulas for the axiom schemes.


\paragraph{Limitations}
This style of formalization will fundamentally not be able to derive proofs about the proof system
itself, as the proof system is Lean itself. However, this \emph{will} be possible in the formalization
due to Forster et al. from Coq Library for First-Order Logic: since they deeply embed the whole
proof system, we surely can prove properties about it in Rocq.

\begin{remark}[Origins of this thesis]
We have only started investigating
bounded arithmetic for our problem in March of 2025 and it was then unclear if the
results from this field will transfer to anything actually computational. 
Only in
July 2025 we have decided to implement the formalization and quickly obtained
a formalization of a prototype finitely axiomatiable theory like in~\autoref{lst:lean-demo}.
In August of 2025 we have obtained
a working version of the full formalization of $\IDeltaZero{}$.
In the first week of September 2025 we have presented our project at AITP2025 conference in
Aussois, France: the main motivation behind the presentation was the importance of creating
proof assistants with theories that are \emph{weaker} than Rocq and Lean's and admitting
better proof-search or code-extraction procedures.
Only later in September of 2025 as part of us visiting Yannick Forster at INRIA Paris,
we have achieved a usable state of the formalization
with a well-thought $\mathtt{simp}$-set for $\IDeltaZero{}$ and interesting
properties proved for $\compVZero{}$ and $\complexityi{VTC}{0}$.
The existence of the $\texttt{Mathlib.ModelTheory}$ library was the thing that enabled us to
achieve our formalization in the scope of this thesis. 
\end{remark}


% \paragraph{Comparison: ways of code extraction}

% \paragraph{Comparison: }


\begin{rawlisting}
\input{listings/lean-demo.tex}
\caption{Core theory behind formalization of arithmetic in Lean.}\label{lst:lean-demo}
\end{rawlisting}





\begin{remark}[Related works]
There is very little work available on the formalization of arithmetic.
A formalization of consistency of Peano arithmetic in Coq was presented in~\cite{O_Connor_2005}.
A formalization of the so-called \emph{Hydra battles} related to unprovability in Peano arithmetic
was shown in~\cite{casteran:hal-03404668}. There is an impressive ongoing project of formalization
of bounded arithmetic in the model-theoretical style in the Lean
community.\footnote{\url{https://github.com/FormalizedFormalLogic/Foundation}} Their approach doesn't
align with our goal of certifying complexity, as their focus is on other arithmetical theories, which differ
significantly from what we need. Somehow related, some work on intuitionistic logic in Lean has also been done
in~\cite{Trufa__2024} even though Lean is not a natural environment for intuitionistic thinking, as it
assumes classical axioms very deeply in its standard libraries, unlike Rocq which is constructive by heart.
\end{remark}




\begin{rawlisting}
\input{listings/lean-example.tex}
\caption{One actual proof formalized in our system}\label{lst:lean-example}
\end{rawlisting}
