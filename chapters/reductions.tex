% todo: coin the term Oracle Oriented Programming
\chapter{Reductions}\label{chap:reductions}
Plenty of theorems of the form ``problem $P$ is \emph{complete} for class $C$ under
reductions in class $R$'' have been described in the literature. In this chapter
we analyze when such reductions help capture complexity classes syntactically
and when they fall short.

% \begin{definition}[Circuit Value Problem (\problem{CVP})]
%   Given a representation of a Boolean circuit on input, compute its output.
%   \todo[inline]{more formality}
% \end{definition}

\begin{theorem}[%
  {\cite{10.1145/990518.990519}}%
]\label{thm:cvp-pcomplete}
  Define the circuit value problem (\problem{CVP}) as the problem of finding the output of a Boolean circuit,
  given its representation as input.
  The circuit value problem is complete for \compP{} under \compL{} reductions.
  \begin{remark}
    We define \compL-reductions formally in~\autoref{def:logspace-reductions}. For the details of
    representation of Boolean circuits, see~\cite{10.1145/990518.990519}.
  \end{remark}
\end{theorem}

Knowing~\autoref{thm:cvp-pcomplete}, we could design a language for \compP{} in such a way:
first, design a language for \compL{} which is (perhaps) simpler; then, as the compiler provider,
include a standard library function \(P\), which
the \compL-functions from the language could call like an oracle to get a solution for \(P\).
In this chapter we try to understand
if such a language would truly have the full power of polynomial-time functions.
The core of this chapter is~\autoref{thm:fl-is-l-red}, stating that this holds at least for the class
of logspace-computable functions and a particular notion of weak reductions. But the heart
of this intuition is not developed until~\autoref{thm:theories-for-classes-from-reductions}, where we get
such characterizations for most of the complexity classes that we consider in this thesis.

\section{Decisional and functional complexity classes}\label{sec:decisional-and-functional-complexity-classes}
We can't answer the question of expressive power of \(\problem{CVP} + \compL \text{-reductions}\)
by comparing it with any decisional class.
Focusing solely on the complexity of Boolean functions
as we did for now e.g.\ in~\autoref{sec:preliminaries-turing} is 
not sufficient to reason about general functions with output.
In this chapter we will introduce the still standard, but less talked about, 
\emph{functional} complexity classes,
that study the complexity of computing general functions \(f : \{0,1\}^\ast \to \{0,1\}^\ast\)
as introduced in~\autoref{sec:preliminaries-turing-functions}. In complexity theory these are
usually implicitly used to define \emph{reductions}. The results
about these classes transfer much better to our interests than results about the decisional complexity
classes. As we discuss in~\autoref{chap:recursion-theory}, programming-language-like characterizations
of decisional complexity classes are far more abundant and predate the characterizations of
functional complexity classes. It is the latter, however, that is viable for our purposes of
designing a programming language.

A thorough overview of complexity classes of functions is described in~\cite{SELMAN1994357}.
A more thorough discussion of decision vs search is in~\cite{10.5555/889581}.

\paragraph{Exponential-length output}
The difference between \compP{} and \compFP{} is obvious when we look at the below example:
\begin{example}
    Running time of any Turing machine computing the function \(x \to 2^x\) for input and output in binary
    is exponential. At the same time, given an input \(x, y\), checking if \(y = 2^x\) is easily in polynomial time.
\end{example}
This problem is, however, usually artificially mitigated by requiring the length \(\len{f(x)}\)
of the function's output to be polynomially bounded as in~\autoref{def:logspace-reductions}.


\paragraph{Self-reducibility}
A common approach in the literature way of defining function problems is to require
an external proof that \(|f(x)|\) is polynomially bounded,
then repeatedly decide if \(i\)-th bit of \(f(x)\) is 0 or 1. For example, let's look at the below

\begin{definition}[{\cites[Definition~4.16]{10.5555/1540612}[Definition~4.14]{DRAFT10.5555/1540612}}~\compL-reductions]\label{def:logspace-reductions}
A function \(f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}\) is said to be
\emph{logspace computable} if
\begin{enumerate}
\item the function \(f\) is \emph{polynomially bounded}, meaning that there exists a
        constant \(c > 0\) such that
        \[
          \len{f(x)} \le \len{x}^{\,c}
          \qquad\text{for all } x \in \{0,1\}^{\ast};
        \]
  \item the following two languages lie in \(\mathsf{L}\):
        \[
          L_{f}
            = \{\,\langle x,i\rangle \mid f(x)_{i} = 1\,\},
          \qquad
          L'_{f}
            = \{\,\langle x,i\rangle \mid i \le \len{f(x)}\,\}.
        \]
\end{enumerate}

In other words, a deterministic \(\bigO(\log \len{x})\)-space machine can, given
\((x,i)\), determine whether \(i\) is within the length of \(f(x)\) and, if so,
whether the \(i\)-th bit of \(f(x)\) is \(1\).

A language \(B\) is \emph{logspace reducible} to a language \(C\), if there exists
a function
\(f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}\) that is logspace
computable and such that \(x \in B\) iff \(f(x) \in C\) for every
\(x \in \{0,1\}^{\ast}\).
\end{definition}


Famously, we can also apply this trick to solve the problem \problem{FSAT}, the corresponding functional
problem to the \problem{SAT} of finding a specific
satisfying assignment with polynomially many calls to the decision procedure \problem{SAT}. 
In general, many functional problems are solvable in polynomial time with polynomially
many calls to their corresponding decisional problems. We say that
problems with that property are \emph{self-reducible}.

However, some search problems are unlikely to be self-reducible.
A good example is the problem of integer factorization, which
is still, as of November 2025, conjectured to not be in \compP{} even despite
the breakthrough result from 2002 in which \problem{PRIME} (decide if $n$ is prime) was proved to be in \compP~\cite{b68c33ca-3366-3b13-8901-69e76cc88da6}.
A particularly important class of such problems is considered in~\autoref{subsubsec:tfnp}.
But first, let's define the classes \complexity{FP} and \complexity{FNP}.

\section{Functional complexity classes}\label{sec:functional-complexity-classes}

% \todo{perhaps define poly-time computable functoins in preliminaries, and here just link to that}
\begin{definition}[{\cites[Section~17.2]{10.5555/1540612}[Section~9.1]{DRAFT10.5555/1540612}}~The class \complexity{FP} (Version 1)]\label{def:fp-ver1}
  \(\mathsf{FP}\)~consists of all functions
\[
  f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}
\]
that are computable by a deterministic polynomial-time Turing machine.
In contrast to decision problems (which output a single bit), functions
in \(\mathsf{FP}\) may produce outputs of arbitrary polynomial length.

\begin{remark}
  This definition is used e.g.\ in~\cite{COOK19852} besides the work cited above.
  It is rather equivalent to~\autoref{def:fp} below, also ubiquitous in the literature.
\end{remark}
\end{definition}

% \todo[inline]{I have a definition of also poly-time reductions e.g. for NP in tex, but seems like i'm not using it anywhere}
\begin{definition}[{\cite[Section 28.10]{Rich2007Automata}}~\complexity{FP} (Version 2)]\label{def:fp}

A binary relation \(P(x, y)\) is in \(\complexity{FP}\) iff there exists a polynomial-time Turing machine $M$
that, given an arbitrary input \(x\):
\begin{enumerate}
    \item there is at most one \(y\) satisfying \(P(x, y)\) (functionality);
    \item outputs some \(y\) such that \(P(x, y)\) if any exists;
    \item signals that no such \(y\) exists otherwise.
\end{enumerate}

\begin{remark}
  This version can make it more obvious to compare \(\complexity{FP}\) with \(\complexity{FNP}\) (defined later) ---
  but only assuming that \(\complexity{FNP}\) is defined using nondeterministic Turing machines,
  which is not true in our case; we will use the \emph{verifier}-style definition.
\end{remark}


% transducers of polynomial growth are studied in~\cite{10.1145/3531130.3533326}, where also
% are given pebble, functinal, impearitve and logical models of computation.
\end{definition}


\begin{remark}[\complexity{P} vs \complexity{FP}]
These two classes are often identified due to similar properties.
The notion of completeness for both of them, despite being differently defined, is practically the same
due to the \(\complexity{P}\) computations being closed under being repeated for every bit of the output.


This conflation already appears in Stephen Cook's 1982 ACM Turing Award
lecture~\cite[Section~6]{10.1145/358141.358144}, where the distinction between \complexity{P}-completeness
and \complexity{FP}-completeness is not made explicit. The three examples cited there as establishing
\complexity{FP}-completeness of certain functions $f(x)$ in fact only prove \complexity{P}-completeness of the
associated decision problems of the form: given $x$ and $i$, decide whether the $i$-th bit of $f(x)$ is zero.

The two classes, however, are not the same.
Define $\complexity{FP}^{\complexity{NP}}[f(n)]$ to be the class of functions
computable in polynomial time given access to call \emph{an oracle}
for an $\complexity{NP}$-complete problem at most $f(n)$ times. For a formal definition of
an \emph{Oracle Turing machine}, please refer to~\cites[Definition~3.4]{10.5555/1540612}[Definition~3.7]{DRAFT10.5555/1540612}.
Define $\complexity{P}^{\complexity{NP}}[f(n)]$ analogously.
In~\cite[Theorem 4.1]{KRENTEL1988490}, it is proved that
if 
\(\complexity{FP}^{\complexity{NP}}[\bigO(\log{n})] = \complexity{FP}^{\complexity{NP}}[n^{\bigO(1)}]\),
then also \(\complexity{P}=\complexity{NP}\).
In turn, as noted in~\cite[discussion after Theorem 8]{doi:10.1142/9789812794499_0029}, the corresponding result for
\(\complexity{P}^\complexity{NP}[\bigO(\log{n})]\) versus \(\complexity{P}^\complexity{NP}[n^{\bigO(1)}]\) is not known,
and indeed fails relative to some oracles.

For a good discussion specifically on \complexity{FP}-completeness,
which is relatively hard to find, there is an argument that finding the lexicographically
first maximal clique in an undirected graph
is \complexityi{NC}{i}-complete for \complexity{FP} in~\cite[Proposition~6.1]{COOK19852}.
\end{remark}

% POLYTIME-REDUCIBILITY
% We will say that a function is \emph{polynomial-time computable} if it is
% computable by a Turing machine running in polynomial time, not using the
% decider trick for \emph{logspace computability} in~\autoref{def:logspace-reductions}.
% \begin{definition}[\compP-reductions~{\cites[Definition~2.7]{10.5555/1540612}[Definition~2.7]{DRAFT10.5555/1540612}}]\label{def:p-reductions}
% Let \(A,B \subseteq \{0,1\}^{\ast}\) be languages.  
% We say that \(A\) is \emph{polynomial-time Karp (many-one) reducible} to \(B\),
% if there exists a polynomial-time
% computable function
% \[
%   f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}
% \]
% such that for every input \(x \in \{0,1\}^{\ast}\),\todo{consistency: \(\iff\) vs \(\Longleftrightarrow\)}
% \[
%   x \in A
%   \;\Longleftrightarrow\;
%   f(x) \in B.
% \]
% In this case, the function \(f\) is called a \emph{polynomial-time reduction}
% from \(A\) to \(B\).
% \end{definition}









\subsection{\complexity{FNP}}
The definition of \complexity{FNP} is tricky to get right.
A very good discussion of the awkwardness of the definitions is present in~\cite{37813}.
For extensive discussion on the different definitions, see~\cite{37812},~\cite{71617}.
In Papadimitriou's book, it's defined in yet another way, as a class of function problems for \complexity{NP},
not in terms of a specific computational model.

\begin{definition}[The class \texorpdfstring{\complexity{FNP}}{FNP}]\label{def:complexity-fnp}
A binary relation \(P(x, y)\) is in \(\complexity{FNP}\) if there exist:
\begin{enumerate}
  \item a polynomial \(p : \mathbb{N} \to \mathbb{N}\) such that if, for a given \(x\), there exists a solution \(y\) such
  that \(P(x, y)\), then there also exists a ``short'' solution \(y'\) such that
  \(P(x, y')\) and \(\len{y'} \leqslant p(\len{x})\);
  \item a deterministic polynomial-time Turing machine \(M\)
        (a \emph{verifier}), 
        such that for every input pair \((x, y)\),\todo{consistency: iff vs Longleftrightarrow}
        \[
            P(x, y)
            \;\Longleftrightarrow\;
            M(x, y) = 1.
            \]
\end{enumerate}

\begin{remark}
  This definition is in style of~\cite[28.10~and~Theorem~28.9]{Rich2007Automata}, where also the
  other, nondeterministic Turing machines-based definition is listed.

  The other definition might come off as more intuitive:
  that a relation $P$ is in \complexity{FNP} iff there is a nondeterministic polynomial-time
  algorithm that, given an arbitrary input $x$,
  can find some $y$ such that $P(x, y)$ or signal that it doesn't exist~\cite{bournez_et_al:LIPIcs.MFCS.2019.23}.
  However, as such nondeterministic Turing machines don't seem to be physically realisable, we don't want to
  introduce that computational model in this work.
\end{remark}

\end{definition}




\subsection{\complexity{NP} vs \complexity{FNP} and the total search problems}\label{subsubsec:tfnp}
\begin{definition}[\complexity{TFNP}]\label{def:tfnp}
A binary relation \(P(x, y)\) is in \(\complexity{TFNP}\) (total \(\complexity{FNP}\)) iff it is
in \(\complexity{FNP}\) and for every \(x\) there exists at least one \(y\) such that \(P(x, y)\).
\end{definition}

An interesting example of a problem in \(\complexity{TFNP}\) is \problem{PIGEON} defined below,
for which we mathematically know that the answer exists, but finding it is not trivial.

\begin{definition}[\problem{PIGEON}]\label{def:pigeon}
Given a binary string encoding a Boolean circuit \(C:\{0,1\}^n\!\to\!\{0,1\}^n\), return either
an input \(x\) such that \(C(x) = 0^n\), or two distinct inputs \(x \neq y\) such that \(C(x) = C(y)\).
\end{definition}

\begin{remark}\label{remark:link-pigeonhole}
    This problem will be of our interest in~\autoref{subsec:vac0-php}, where we will discuss mathematical theories
    so weak that the pigeonhole principle is not their theorem. The intuition behind it is that
    the computational content of these theories is not strong enough to perform an exhaustive
    linear search of the whole domain.
\end{remark}

The class \complexity{PPP}, a subclass of \complexity{TFNP} problems for which the solution is
guaranteed to exist by the pigeonhole principle, is conjectured to not be equal to \complexity{FP}.
If \(\complexity{PPP} = \complexity{FP}\), then one-way permutations do not exist~\cite[Proposition~3]{PAPADIMITRIOU1994498},
which would have tremendous implications for cryptography.

The class \complexity{TFNP} is discussed in yet more detail in~\cite[Section 1.1]{10.5555/1104410}.







% CIRCUIT-REDUCIBILITY
% uniform FAC0 does NOT admit a nice circuit characterization. FAC0/poly
% is standard (see LogicalFoundations Definition V.2.3) circuits with output.
% But the notion of uniformity doesn't generalize to circuits with outputs!
% Our only hope is in ``polynomial number of AC0-decidable outputs''!

% FAC0 vs AC0-reduction: Definition IX.1.1: AC0-reductions are Turing reductions
% and are circuits with oracle gates for some problem L!
% Section IX.2.1: if C is relations ac0-reducible to F, then FC is FAC0 closure of F.


% \section{\texorpdfstring{$\complexityi{AC}{0}$-reduction}{AC\string^0-reduction}}
% \label{sec:ac0red}
% Definition IX.1.1 CN10. We say that a string function F
% (resp. \  a number function f) is $\complexityi{AC}{0}$-reducible to $L$ if there is a sequence
% of string functions $F_1, \dots, F_n (n \geqslant 0)$ such that
% $F_i$ is $\Sigma^B_0$-definable from $L \cup \{F_1, \dots , F_{i-1}\}$, for $i = 1, \dots, n$
% and F (resp. \ f) is $\Sigma^B_0$-definable from $L \cup \{F_1, \dots , F_{i-1}\}$. A relation R is
% $\complexityi{AC}{0}$-reducible to $L$ if there is a sequence $F_1, \dots, F_n$ as above, and R is
% represented by a $\Sigma^B_0(L \cup \{F_1, \dots, F_n\})$ formula.

% In Chapter~2 of~\cite{edbd4873718c414f90d22dadf0dba2b1} there is an extensive discussion about
% the different subtleties of defining $\complexityi{AC}{0}$ functions and numerous different characterizations
% of Dlogtime-uniform $\complexityi{AC}{0}$-computable functions.


\subsection{Language for \complexity{FL}}
% \todo[inline]{I really don't want to introduce circuit reductions... skipping it.}

\begin{theorem}[{\cite[Proposition~4.1]{COOK19852}}]\label{thm:fl-is-l-red}
  We obtain precisely the class \complexity{FL} from the closure of \compL{} under \complexityi{NC}{1} circuit reductions,
  symbolically: \(\complexity{FL} = \complexity{L}^\ast\)
  
  \begin{remark}
    Originally, this theorem is proved with \complexityi{NC}{1}-reducibility meaning
    reducibility by \compUeAst-uniform \complexityi{NC}{1} circuits. We don't introduce these
    notions in this work (except for a brief discussion of \compUeAst-uniformity in~\autoref{sec:uniformity-ueast})
  \end{remark}
\end{theorem}

An overview of problems complete for \compL{} is present in~\cite{COOK1987385}.

\subsection{Language for \complexity{FP}}
We can derive a similar result (but in a slightly different setting) to~\autoref{thm:fl-is-l-red} for the class \complexity{FP}.
For now we are just mentioning it. We will discuss this in more detail in~\autoref{thm:theories-for-classes-from-reductions}.

% # Circuit Value Problem
% - For a given single-tape, polynomial-time Turing machine `M` and input `x`, in [@Kozen2006],
% there is an explicit construction of a boolean circuit over (0, 1, `and`, `or`, `not`)
% (with fan-in 2 for `and`, `or` and 1 for `not`), with one output node, such that its value
% is 1 if and only if machine `M` accepts input `x`. The construction is in LOGSPACE.
% So CVP is P-complete w.r.t. LOGSPACE-reductions.
% - This is a good example of a LOGSPACE-reduction, being a good benchmark for the LF programming
% language and for the circuit description language
% - The problem is that we can't generate tests for it; we have no database of Turing machines descriptions
The notion of \compP-completeness is defined formally e.g.\ in~\cites[Definition~6.25]{DRAFT10.5555/1540612}[Definition~6.28]{10.5555/1540612}.
A very detailed description of one problem complete for \compP{} under \compL-reductions is in~\cite{Kozen2006}.

\subsection{Not-a-Language for \complexity{FNP}}
There is a relatively agreed-upon notion of reductions between \complexity{FNP} problems:

\begin{definition}[{\cites{Goebel2011NashComplexity}{Goldberg2021SearchTotal}}~Polynomial-time reductions for \complexity{FNP}]
    Let \(\texttt{HardProblem}\), \(\texttt{NewProblem}\) be search problems in \(\complexity{FNP}\).
    We say that \(\texttt{HardProblem}\) (many-one) reduces to \(\texttt{NewProblem}\) if there exist
    \(f, g\) in \complexity{FP} such that:
    \[\texttt{NewProblem}(f(x), y) \Longleftrightarrow \texttt{HardProblem}(x, g(y))\]

    For a given input \(x\) of \(\texttt{HardProblem}\), we can run \(\texttt{NewProblem}(f(x))\)
    to obtain some result \(y\), such that \(g(y)\) is the result of \(\texttt{HardProblem}(x)\).
\end{definition}

There are also plenty of \complexity{NP}-complete problems described in the literature.
However, it is very unclear if we will get \complexity{FNP} this way. The class 
\(\complexity{FP}^{\complexity{NP}}\) is well-studied and nothing suggests it to be equal to \complexity{FNP}.


\subsection{Semantic and syntactic complexity classes}

Some of the popular complexity classes are defined in such a way that it is notoriously difficult to
exhibit natural complete problems for them. A complexity class is called \emph{syntactic}
if it admits a natural notion of completeness, that is, if there exists a problem that is complete
for the class under the chosen reductions. Classes for which no such complete problems are known are
often called \emph{semantic}. For example, in~\cite{DBLP:conf/innovations/GoldbergP18} the authors introduce
a new complexity
class $\complexity{PTFNP} \subseteq \complexity{TFNP}$, prove that it has a complete problem,
and therefore refer to $\complexity{PTFNP}$ as a syntactic subclass of $\complexity{TFNP}$.

An interesting discussion of the absence of complete problems, centred around the class
$\complexity{inv\text{-}P}$ introduced in~\autoref{subsec:unordered-structures}, is
given in~\cite{dawar2012syntactic}. For the class $\complexity{BPP}$, related issues are
discussed in~\cite{35236}. Despite $\complexity{BPP}$ being believed to be semantic,
a characterization of it (not purely syntactic) was
studied in~\cite{lago2012higherordercharacterizationprobabilisticpolynomial}.
Interestingly, \complexity{PP} has been characterized implicitly
(i.e.\ syntactically) by Ugo Dal Lago:~\cite{dallago_et_al:LIPIcs.MFCS.2021.35}.


\begin{remark}[Bibliography]
For probably the first published recognition of the widespread inconsistency between decisional and functional
complexity classes in the literature, with examples of inconsistent places see~\cite[Page~131]{10.5555/114872}
(and our bibliographical~\autoref{remark:bibliography-david-s-johnson}).

\(\complexity{TFNP}\) was first introduced in~\cite{MEGIDDO1991317}.
\end{remark}





\subsection{Oracle Turing machines and the technique of forcing}\label{subsec:oracle-forcing}
Notice that programming in this chapter we essentially try to introduce a new style of programming, where
when we want to write a program in \complexity{P}, we write most of the functions in a (simpler) language
for \compL-reductions, and sometimes pass their results to some special function implementing a \complexity{P}-complete
algorithm. 
In the literature, such a ``special function'' is sometimes called an \emph{oracle}.
Please see~\cites[Definition~3.4]{10.5555/1540612}[Definition~3.7]{DRAFT10.5555/1540612} for a formal definition
of Oracle Turing machines. 
This would introduce a new programming paradigm, \emph{oracle-oriented} programming, utilizing
the notion of \emph{oracle} from the literature. In this thesis we were not able to showcase this paradigm,
it will, however, be the ultimate direction of our further works.

Here we only want to hint that a strong technique called \emph{forcing} can be used in a similar manner
in both set theory and computational complexity. For information on the technique of forcing in complexity theory, please see~\cite{14093} for
discussion in context of the Baker-Gill-Solovay theorem\footnote{The Baker-Gill-Solovay theorem is studied e.g.\ in~\cites[Theorem~3.9]{DRAFT10.5555/1540612}[Theorem~3.7]{10.5555/1540612}.}; \cite{jaberhal-00685150}~for viewing forcing
as a program transformation technique.
For general information on the forcing technique, more focused on set theory, please see e.g.~\cite{chow2008beginnersguideforcing}.


% ### Proving unprovability: Kripke semantics
% - even though searching for a countermodel in Kripke semantics is completely infeasible computationally, we have a good tool for the job!
% - i tested and it works, find countermodels and proofs of intuitionistic formulas. code: https://github.com/ferram/jtabwb_provers/tree/master




\subsection{Fine-grained reductions}\label{subsec:fine-grained-reductions}
Ideally, we would measure the time and space complexity of algorithms more precisely than
up to a polynomial. In practice, we are the most interested in complexity bounds such
as $\complexity{DTIME}(\bigO(n^2))$. However, the field of studying syntactical characterizations
of such functions is still mostly undiscovered. In~\cite{10.1145/167088.167244}, some problems
complete for nondeterministic linear time are studied. In~\cite{10.1007/3-540-51237-3_10},
the notion of \complexity{QL} reductions is introduced to study complete problems for ``nearly linear time'',
i.e.\ $\complexity{DTIME}(n (\log{n})^{\bigO(1)})$.







% \item TODO: Example programming language characterizing \complexity{L}: finite number of variables each bounded by $n$.
% \item TODO: Explore the alternative characterization using a finite number of input pointers, relating it to multi-head two-way automata~\cite{423885},~\cite{10.1007/BF00289513}.

% \subsection{Related works on specifically the \complexity{FL} class}
% Early function algebras for \complexity{FL} appeared in~\cite{10.1145/1008293.1008295} and~\cite{lind1974logspace},
% but these were explicit characterizations.
% In~\cite{10.1007/BF01201998} it was shown how to readily use their concept
% to characterize functions from \complexity{FL} with ``small output'', but this characterization
% relied on using unary representation of natural numbers on input, which is more of a 
% hack than a true characterization of this class.
% In~\cite{murawski2000can}, with further refinements in~\cite{MURAWSKI2004197},
% \(BC^{-}\) was introduced, an algebra that was contained in \complexity{FL},
% but was not known (and unlikely) to be \complexity{FL}-complete.
% In~\cite{Neergaard04} this was improved to the result that \(BC_\varepsilon^{-} = \complexity{FL}\),
% with a short discussion that using course-of-value affine recursion instead of predicative affine recursion
% seem to be the reason behind \(BC_\varepsilon^{-}\) being FL-complete, and \(BC^{-}\) being probably not.

% In~\cite{4276584}, Stratified Bounded Affine Logic is introduced to capture \complexity{FL} computation.
% In~\cite{10.1007/978-3-662-46678-0_27}, an interesting approach using coinduction is utilized to capture \complexity{FL}.

% In~\cite{hofmann2006logspace} a good overview of languages for \complexity{FL} is presented,
% and in~\cite{schoepp2006spaceefficiency}, the history of \complexity{FL} characterizations is traced.
