% todo: coin the term Oracle Oriented Programming
\chapter{Reductions}\label{chap:reductions}
Plenty of theorems of the form ``problem $P$ is \emph{complete} for class $C$ under
reductions in class $R$'' have been described in the literature. In this chapter
we analyze when are they useful to capture complexity classes syntactically,
and when they don't suffice.

\begin{definition}[Circuit Value Problem (\problem{CVP})]
  Given a representation of a Boolean circuit on input, compute its output.
  \todo[inline]{more formality}
\end{definition}

\begin{theorem}[%
  {\cite{10.1145/990518.990519}}%
]\label{thm:cvp-pcomplete}
  The circuit value problem is complete for \compP{} under \compL{} reductions.
  \begin{remark}
    We define \compL-reductions formally in~\autoref{def:logspace-reductions}.
  \end{remark}
\end{theorem}

Knowing~\autoref{thm:cvp-pcomplete}, we could design a language for \compP{} in such a way:
first, design a language for \compL{} which is (perhaps) simpler; then, as the compiler provider,
include a standard library function \(P\), which
the \compL-functions from the language could call like an oracle to get solution for \(P\).
In this chapter we try to understand
if such a language would truly have the full power of polynomial-time functions.
The core of this chapter is~\autoref{thm:fl-is-l-red}, stating that this holds at least for the class
of logspace-computable functions and a particular notion of weak reductions. But the heart
of this intuition is not developed until~\autoref{thm:fc-is-fac0-closure}, where we get
such characterizations for most of the complexity classes that we consider in this thesis.

\section{Decisional and functional complexity classes}\label{sec:decisional-and-functional-complexity-classes}
We can't answer the question of expressive power of \(\problem{CVP} + \compL \text{-reductions}\)
by comparing it with any decisional class.
Focusing solely on the complexity of Boolean functions
as we did for now e.g.\ in~\autoref{sec:preliminaries-turing} is 
not sufficient to reason about general functions with output.
In this chapter we will introduce the still standard, but less talked about, 
\emph{functional} complexity classes,
that study general functions \(f : \{0,1\}^\ast \to \{0,1\}^\ast\). In complexity theory these are
usually implicitly used to define \emph{reductions}. The results
about these classes  transfer much better to our interests than results about the decisional complexity
classes. As we discuss  in~\autoref{chap:recursion-theory}, programming-language-like characterizations
of decisional complexity classes are far more abundant and predate the characterizations of
functional complexity classes. It is the latter, however, that is viable for our purposes of
designing a programming language.

A thorough overview of complexity classes of functions is described in~\cite{SELMAN1994357}.
A more thorough discussion of decision vs search is in~\cite{10.5555/889581}.

\paragraph{Exponential-length output}
The difference between \compP{} and \compFP{} is obvious when we look at the below example:
\begin{example}
    Running time of any Turing machine computing the function \(x \rightarrow 2^x\) for input and output in binary,
    is exponential. At the same time, given an input \(x, y\), checking if \(y = 2^x\) is easily in polynomial time.
\end{example}
This problem is, however, usually artificially mitigated by requiring the length \(|f(x)|\)
of the function's output to be polynomially bounded as in~\autoref{def:logspace-reductions}.


\paragraph{Self-reducibility}
A typical, and ubiquitous in the literature way of defining function problems is to require
an external proof that \(|f(x)|\) is polynomially bounded,
then repeatedly decide if \(i\)-th bit of \(f(x)\) is 0 or 1. For example, let's look at the below

\begin{definition}[{\cites[Definition~4.16]{10.5555/1540612}[Definition~4.14]{DRAFT10.5555/1540612}}~\compL-reductions]\label{def:logspace-reductions}
A function \(f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}\) is said to be
\emph{logspace computable} if
\begin{enumerate}
  \item \(f\) is \emph{polynomially bounded}, meaning that there exists a
        constant \(c > 0\) such that
        \[
          |f(x)| \le |x|^{\,c}
          \qquad\text{for all } x \in \{0,1\}^{\ast},
        \]
        and
  \item the following two languages lie in \(\mathsf{L}\):
        \[
          L_{f}
            = \{\,\langle x,i\rangle \mid f(x)_{i} = 1\,\},
          \qquad
          L'_{f}
            = \{\,\langle x,i\rangle \mid i \le |f(x)|\,\}.
        \]
\end{enumerate}

In other words, a deterministic \(\bigO(\log |x|)\)-space machine can, given
\((x,i)\), determine whether \(i\) is within the length of \(f(x)\) and, if so,
whether the \(i\)-th bit of \(f(x)\) is \(1\).

A language \(B\) is \emph{logspace reducible} to a language \(C\), if there exists
a function
\(f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}\) that is logspace
computable and such that \(x \in B\) iff \(f(x) \in C\) for every
\(x \in \{0,1\}^{\ast}\).
\end{definition}


Famously, we can also apply this trick to solve the problem \problem{FSAT}, the corresponding functional
problem to the \problem{SAT} of finding a specific
satisfying assignment with polynomially many calls to the decision procedure \problem{SAT}. 
In general, many functional problems are solvable in polynomial time with polynomially
many calls to their corresponding decisional problems. We say that
problems with that property are \emph{self-reducible}.

However, some search problems are unlikely to be self-reducible.
A good example is the problem of integer factorization, which
is still, as of November 2025, conjectured to not be in \compP even despite
the recent breakthrough in which \problem{PRIME} was proved to be in \compP.
A particularly important class of such problems is considered in~\ref{subsubsec:tfnp}.
But first, let's define the classes \complexity{FP} and \complexity{FNP}.

\section{Functional complexity classes}\label{sec:functional-complexity-classes}

\todo{perhaps define poly-time computable functoins in preliminaries, and here just link to that}
\begin{definition}[{\cites[Section~17.2]{10.5555/1540612}[Section~9.1]{DRAFT10.5555/1540612}}~The class \complexity{FP} (Version 1)]\label{def:fp-ver1}
  \(\mathsf{FP}\)~consists of all functions
\[
  f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}
\]
that are computable by a deterministic polynomial-time Turing machine.
In contrast to decision problems (which output a single bit), functions
in \(\mathsf{FP}\) may produce outputs of arbitrary polynomial length.

\begin{remark}
  This definition is used e.g.\ in~\cite{COOK19852} besides the work cited above.
  It is rather equivalent to~\autoref{def:fp} below, also ubiquitous in the literature.
\end{remark}
\end{definition}

\todo[inline]{I have a definition of also poly-time reductions e.g. for NP in tex, but seems like i'm not using it anywhere}
\begin{definition}[{\cite[Section 28.10]{Rich2007Automata}}~\complexity{FP} (Version 2)]\label{def:fp}

A binary relation \(P(x, y)\) is in \(\complexity{FP}\) iff there exists a polynomial-time Turing machine
that, given an arbitrary input \(x\):
\begin{enumerate}[label=(\roman*)]
    \item outputs some \(y\) such that \(P(x, y)\) if any exists;
    \item signals that no such \(y\) exists otherwise.
\end{enumerate}

\begin{remark}
  This version can make it more obvious to compare \(\complexity{FP}\) with \(\complexity{FNP}\) (defined later) ---
  but only assuming that \(\complexity{FNP}\) is defined using nondeterministic Turing machines,
  which is not true in our case; we will use the \emph{verifier}-style definition.
\end{remark}


% transducers of polynomial growth are studied in~\cite{10.1145/3531130.3533326}, where also
% are given pebble, functinal, impearitve and logical models of computation.
\end{definition}


\begin{remark}[\complexity{P} vs \complexity{FP}]
These two classes are often identified due to similar properties.
The notion of completeness for both of them, despite being differently defined, practically is practically the same
to the robustness of \(\complexity{P}\) computations under being repeated for every bit of the output.
Indeed, even in Stephen Cook's 1982 ACM Turing Award lecture~\cite[Section 6]{10.1145/358141.358144},
it is not clearly distinguished between
\(\complexity{P}\)-completeness and \(\complexity{FP}\)-completeness: the 3 proofs cited in this lecture
as proofs of \(\complexity{FP}\)-completeness of some functions \(f(x)\) only themselves prove the
\(\complexity{P}\)-completeness of problems of the form ``decide if \(i\)-th bit of the result \(f(x)\) is zero''.

The two classes, however, are not the same.
In~\cite[Theorem 4.1]{KRENTEL1988490}, it is proved that
if 
\(\complexity{FP}^{\complexity{SAT}}[\bigO(\log{n})] = \complexity{FP}^{\complexity{SAT}}[n^{\bigO(1)}]\)
then also \(\complexity{P}=\complexity{NP}\).
In turn, as noted in~\cite[discussion after Theorem 8]{doi:10.1142/9789812794499_0029}, the corresponding result for
\(\complexity{P}^\complexity{NP}\) versus \(\complexity{P}^\complexity{NP}[\bigO(\log{n})]\) is not known,
and indeed fails relative to some oracles.

For a good discussion specifically on \complexity{FP}-completeness,
which is relatively hard to find, there is an argument that finding the lexicographically
first maximal clique in an undirected graph
is \complexityi{NC}{i}-complete for \complexity{FP} in~\cite[Proposition~6.1]{COOK19852}.
\end{remark}

% POLYTIME-REDUCIBILITY
% We will say that a function is \emph{polynomial-time computable} if it is
% computable by a Turing machine running in polynomial time, not using the
% decider trick for \emph{logspace computability} in~\autoref{def:logspace-reductions}.
% \begin{definition}[\compP-reductions~{\cites[Definition~2.7]{10.5555/1540612}[Definition~2.7]{DRAFT10.5555/1540612}}]\label{def:p-reductions}
% Let \(A,B \subseteq \{0,1\}^{\ast}\) be languages.  
% We say that \(A\) is \emph{polynomial-time Karp (many-one) reducible} to \(B\),
% if there exists a polynomial-time
% computable function
% \[
%   f : \{0,1\}^{\ast} \to \{0,1\}^{\ast}
% \]
% such that for every input \(x \in \{0,1\}^{\ast}\),\todo{consistency: \(\iff\) vs \(\Longleftrightarrow\)}
% \[
%   x \in A
%   \;\Longleftrightarrow\;
%   f(x) \in B.
% \]
% In this case, the function \(f\) is called a \emph{polynomial-time reduction}
% from \(A\) to \(B\).
% \end{definition}









\subsection{\complexity{FNP}}
The definition of \complexity{FNP} is tricky to get right.
A very good discussion of the awkwardness of the definitions is present in~\cite{37813}.
For extensive discussion on the different definitions, see~\cite{37812},~\cite{71617}.
In Papadimitriou's book, it's defined in yet another way, as a class function problems for \complexity{NP},
not in terms of a specific computational model.

\begin{definition}[The class \texorpdfstring{\complexity{FNP}}{FNP}]\label{def:complexity-fnp}
A binary relation \(P(x, y)\) is in \(\complexity{FNP}\) if there exist:
\begin{enumerate}
  \item a polynomial \(p : \mathbb{N} \to \mathbb{N}\) such that if for a given \(x\) exists a solution \(y\) such
  that \(P(x, y)\), then there also exist a ``short'' solution \(y'\) such that
  \(P(x, y')\) and \(|y'| \leqslant p(|x|)\);
  \item a deterministic polynomial-time Turing machine \(M\)
        (a \emph{verifier}), 
        such that for every input pair \((x, y)\),
        \[
            P(x, y)
            \;\Longleftrightarrow\;
            M(x, y) = 1.
            \]
\end{enumerate}

\begin{remark}
  This definition is in style of~\cite[28.10~and~Theorem~28.9]{Rich2007Automata}, where also the
  other, nondeterministic Turing machines-based definition is listed.

  The other definition might come off as more intuitive:
  that a relation $P$ is in \complexity{FNP} iff there is a nondeterministic polynomial-time
  algorithm that, given an arbitrary input $x$,
  can find some $y$ such that $P(x, y)$ or signal that it doesn't exist~\cite{bournez_et_al:LIPIcs.MFCS.2019.23}.
  However, as such nondeterministic Turing machines don't seem to be physically realisable, we don't want to
  introduce that computational model in this work.
\end{remark}

\end{definition}




\subsection{\complexity{NP} vs \complexity{FNP} and the total search problems}\label{subsubsec:tfnp}
\begin{definition}[\complexity{TFNP}]\label{def:tfnp}
A binary relation \(P(x, y)\) is in \(\complexity{TFNP}\) (total \(\complexity{FNP}\)) iff it is
in \(\complexity{FNP}\) and for every \(x\) exists at least one \(y\) such that \(P(x, y)\).
\end{definition}

An interesting example of a problem in \(\complexity{TFNP}\) is \problem{PIGEON} defined below,
for which we mathematically know that the answer exists, but finding it is not trivial.

\begin{definition}[\problem{PIGEON}]\label{def:pigeon}
Given a binary string encoding a Boolean circuit \(C:\{0,1\}^n\!\to\!\{0,1\}^n\), return either
an input \(x\) such that \(C(x) = 0^n\), or two distinct inputs \(x \neq y\) such that \(C(x) = C(y)\).
\end{definition}

\begin{remark}\label{remark:link-pigeonhole}
    This class will be of our interest in~\autoref{subsec:vac0-php}, where we will discuss mathematical theories
    so weak that the pigeonhole principle is not their theorem. The intuition behind it is that
    the computational content of these theories is not strong enough to perform an exhaustive
    linear search of the whole domain.
\end{remark}

The class \complexity{PPP}, a subclass of \complexity{TFNP} problems for which the solution is
guaranteed to exist by the pigeonhole principle, is conjectured to not be equal to \complexity{FP}.
If \(\complexity{PPP} = \complexity{FP}\), then one-way permutations do not exist~\cite[Proposition~3]{PAPADIMITRIOU1994498},
which would have tremendous implications for cryptography.

The class \complexity{TFNP} is discussed in yet more detail in~\cite[Section 1.1]{10.5555/1104410}.







% CIRCUIT-REDUCIBILITY
% uniform FAC0 does NOT admit a nice circuit characterization. FAC0/poly
% is standard (see LogicalFoundations Definition V.2.3) circuits with output.
% But the notion of uniformity doesn't generalize to circuits with outputs!
% Our only hope is in ``polynomial number of AC0-decidable outputs''!

% FAC0 vs AC0-reduction: Definition IX.1.1: AC0-reductions are Turing reductions
% and are circuits with oracle gates for some problem L!
% Section IX.2.1: if C is relations ac0-reducible to F, then FC is FAC0 closure of F.


% \section{\texorpdfstring{$\complexityi{AC}{0}$-reduction}{AC\string^0-reduction}}
% \label{sec:ac0red}
% Definition IX.1.1 CN10. We say that a string function F
% (resp. \  a number function f) is $\complexityi{AC}{0}$-reducible to $L$ if there is a sequence
% of string functions $F_1, \dots, F_n (n \geqslant 0)$ such that
% $F_i$ is $\Sigma^B_0$-definable from $L \cup \{F_1, \dots , F_{i-1}\}$, for $i = 1, \dots, n$
% and F (resp. \ f) is $\Sigma^B_0$-definable from $L \cup \{F_1, \dots , F_{i-1}\}$. A relation R is
% $\complexityi{AC}{0}$-reducible to $L$ if there is a sequence $F_1, \dots, F_n$ as above, and R is
% represented by a $\Sigma^B_0(L \cup \{F_1, \dots, F_n\})$ formula.

% In Chapter~2 of~\cite{edbd4873718c414f90d22dadf0dba2b1} there is an extensive discussion about
% the different subtleties of defining $\complexityi{AC}{0}$ functions and numerous different characterizations
% of Dlogtime-uniform $\complexityi{AC}{0}$-computable functions.

\begin{definition}
  \todo[inline]{I really don't want to introduce circuit reductions... skipping it.}
\end{definition}


\subsection{Language for FL}

\begin{theorem}[{\cite[Proposition~4.1]{COOK19852}}]\label{thm:fl-is-l-red}
  We obtain precisely the class \complexity{FL} from the closure of \compL under \complexityi{NC}{1} circuit reductions,
  symbolically: \(\complexity{FL} = \complexity{L}^\ast\)
  
  \begin{remark}
    Originally, this theorem is proved with \complexityi{NC}{1}-reducibility meaning
    reducibility by \compUeAst-uniform \complexityi{NC}{1} circuits. We don't introduce these
    notions in this work (except for a brief discussion of \compUeAst-uniformity in~\autoref{sec:uniformity-ueast})
  \end{remark}
\end{theorem}

An overview of problems complete for \compL is present in~\cite{COOK1987385}.

\subsection{Language for \complexity{FP}}
We can derive an analogous result to~\autoref{thm:fl-is-l-red} for the class \complexity{FP}.
We are discussing it here, postponing the considerations to~\autoref{thm:fc-is-fac0-closure}.

% # Circuit Value Problem
% - For a given single-tape, polynomial-time Turing machine `M` and input `x`, in [@Kozen2006],
% there is an explicit construction of a boolean circuit over (0, 1, `and`, `or`, `not`)
% (with fan-in 2 for `and`, `or` and 1 for `not`), with one output node, such that its value
% is 1 if and only if machine `M` accepts input `x`. The construction is in LOGSPACE.
% So CVP is P-complete w.r.t. LOGSPACE-reductions.
% - This is a good example of a LOGSPACE-reduction, being a good benchmark for the LF programming
% language and for the circuit description language
% - The problem is that we can't generate tests for it; we have no database of Turing machines descriptions
The notion of \compP-completeness is defined formally e.g.\ in~\cites[Definition~6.25]{DRAFT10.5555/1540612}[Definition~6.28]{10.5555/1540612}.
A very detailed description of one problem complete for \compP under \compL-reductions is in~\cite{Kozen2006}.

\subsection{Not-a-Language for \complexity{FNP}}
There is a relatively agreed-upon notion of reductions between \complexity{FNP} problems:

\begin{definition}[{~\cites{Goebel2011NashComplexity}{Goldberg2021SearchTotal}}~Polynomial-time reductions for \complexity{FNP}]
    Let \(\texttt{HardProblem}\), \(\texttt{NewProblem}\) be search problems in \(\complexity{FNP}\).
    We say that \(\texttt{HardProblem}\) (many-one) reduces to \(\texttt{NewProblem}\) if there exist
    \(f, g\) in \complexity{FP} such that:
    \[\texttt{NewProblem}(f(x), y) \implies \texttt{HardProblem}(x, g(y))\]

    For a given input \(x\) of \(\texttt{HardProblem}\), we can run \(\texttt{NewProblem}(f(x))\)
    to obtain some result \(y\), such that \(g(y)\) is the result of \(\texttt{HardProblem}(x)\).
\end{definition}

There is also plenty of \complexity{NP}-complete problems described in the literature.
However, it is very unclear if we will get \complexity{FNP} this way. The class 
\(\complexity{FP}^{\complexity{NP}}\) is well-studied and nothing suggests it to be equal to \complexity{FNP}.


\subsection{Semantic and syntactic complexity classes}
Some of the complexity classes remain notoriously difficult to be characterized implicitly,
by e.g.\ showing a complete problem and reductions for it.
However, as it turns out, not all complexity classes studied have known
complete problems.
The classes for which a complete problem exists are called ``syntactic'' complexity classes,
as opposed to ``semantic'', e.g.~in~\cite{DBLP:conf/innovations/GoldbergP18}, the authors define a new complexity class
\(\complexity{PTFNP \subseteq \complexity{TFNP}}\), for which
they prove the existence of a complete problem, and then call this class ``syntactic''.

An interesting discussion of this problem, centered around the class \complexity{inv-P}
we discussed in~\autoref{remark:unordered-structures}, is present in~\cite{dawar2012syntactic}.
For the class \complexity{BPP}, some discussion is in~\cite{35236}.
Despite that, a ``less implicit'' characterization of BPP was studied in~\cite{lago2012higherordercharacterizationprobabilisticpolynomial}.

Interestingly, PP has been characterized implicitly by Ugo Dal Lago:~\cite{dallago_et_al:LIPIcs.MFCS.2021.35}.



\begin{remark}[Bibliography]
For probably the first published recognition of the widespread inconsistency of decisional vs functional
complexity classes in the literature, with examples of inconsistent places see~\cite[Page~131]{10.5555/114872}
(and our bibliographical~\autoref{remark:bibliography-david-s-johnson}).

\(\complexity{TFNP}\) was first introduced in~\cite{MEGIDDO1991317}.
\end{remark}







\section{Oracle-oriented programming}
If you use reductions + a single oracle for a difficult problem, you can get
a powerful programming language. This would be a new, nice paradigm that I aimed to
realize.

Due to possible quadratic blowup of output size (even for ac0 circuits i think? but maybe not if fo-uniform?),
it is unsatisfactory for us to have a single complete problem solving e.g. sat in worst-time \(2^n\).
Because then it gets \(2^{n^2}\) etc., which is bad. Transductions (or fine-grained time complexity classes
such as dlintime) are a potential nice class for this.

\subsection{Oracle Turing machines and the technique of forcing}\label{subsec:oracle-forcing}
\todo[inline]{optional. Baker-Gill-Solovay proof uses forcing. }
% Some discussion in~\cite{14091}.



% ### Proving unprovability: Kripke semantics
% - even though searching for a countermodel in Kripke semantics is completely infeasible computationally, we have a good tool for the job!
% - i tested and it works, find countermodels and proofs of intuitionistic formulas. code: https://github.com/ferram/jtabwb_provers/tree/master

% ### Proving unprovability: forcing
% - Extending Type Theory with Forcing (INRIA, 2012)
% > Implementation of forcing in Coq as a program transformation and show a proof of the negation of CH  
% > https://hal.science/hal-00685150/document

% - A beginnerâ€™s guide to forcing
% > https://arxiv.org/pdf/0712.1320

% - Forcing for dummies blogpost
% > https://timothychow.net/mathstuff/forcingdum.txt

% - Baker-Gill-Solovay theorem proof
% > Forcing as a method to prove that something can or cannot be done using an oracle  
% > https://math.stackexchange.com/questions/2616541/simple-applications-of-forcing-in-recursion-theory  
% > https://en.wikipedia.org/wiki/Forcing_(computability)

% forcing zeby badac jezyki programowania: to jak oracles w computational complexity!
% https://cstheory.stackexchange.com/a/14093
% see here for oracle A such that NEXP^A = P^{NP^{A}}
% what it means in logic when you have P^A,B vs P^A^B?
% https://link.springer.com/article/10.1007/s00037-001-8190-2




\subsection{Fine-grained reductions}\label{subsec:fine-grained-reductions}
% We will not realistically capture $\text{TIME}(\bigO(n))$ or anything of this kind,
% as the field of fine-grained complexity is relatively modern and little or none interesting
% characterizations of these classes have been found as of writing this work.
% \begin{enumerate}
% \item TODO: Review Neil D. Jones's ``Constant Time Factors Do Matter'' for its discussion of NLIN-complete problems (\url{https://dl.acm.org/doi/pdf/10.1145/167088.167244}).
% \item TODO: Summarize the insights from Gurevich and Shelah's ``Nearly Linear Time'' concerning the definition of $\complexity{DTIME}(n)$ and nearly-linear-time-complete problems under QL reductions (\url{https://link.springer.com/content/pdf/10.1007/3-540-51237-3_10.pdf}).
% \end{enumerate}
\todo[inline]{just mention QL (quasilinear-time functions), NLT (robust complexity class for 
    \( \complexity{DTIME} (n (\log{n})^{\bigO(1)}) \) 
    on RAM machines~\cite{10.1007/3-540-51237-3_10})
}




% \item TODO: Example programming language characterizing \complexity{L}: finite number of variables each bounded by $n$.
% \item TODO: Explore the alternative characterization using a finite number of input pointers, relating it to multi-head two-way automata~\cite{423885},~\cite{10.1007/BF00289513}.



% \subsection{Related works on specifically the \complexity{FL} class}
% Early function algebras for \complexity{FL} appeared in~\cite{10.1145/1008293.1008295} and~\cite{lind1974logspace},
% but these were explicit characterizations.
% In~\cite{10.1007/BF01201998} it was shown how to readily use their concept
% to characterize functions from \complexity{FL} with ``small output'', but this characterization
% relied on using unary representation of natural numbers on input, which is more of a 
% hack than a true characterization of this class.
% In~\cite{murawski2000can}, with further refinements in~\cite{MURAWSKI2004197},
% \(BC^{-}\) was introduced, an algebra that was contained in \complexity{FL},
% but was not known (and unlikely) to be \complexity{FL}-complete.
% In~\cite{Neergaard04} this was improved to the result that \(BC_\varepsilon^{-} = \complexity{FL}\),
% with a short discussion that using course-of-value affine recursion instead of predicative affine recursion
% seem to be the reason behind \(BC_\varepsilon^{-}\) being FL-complete, and \(BC^{-}\) being probably not.

% In~\cite{4276584}, Stratified Bounded Affine Logic is introduced to capture \complexity{FL} computation.
% In~\cite{10.1007/978-3-662-46678-0_27}, an interesting approach using coinduction is utilized to capture \complexity{FL}.

% In~\cite{hofmann2006logspace} a good overview of languages for \complexity{FL} is presented,
% and in~\cite{schoepp2006spaceefficiency}, the history of \complexity{FL} characterizations is traced.
