\chapter{Introduction}

\todo[inline]{This will be refined. Now it's just essentials}
The purpose of this thesis is to find a convenient way of certifying that a given program
is in some complexity class. We want to do it by defining such a programming language,
that by definition every program written in it has a given complexity.

\begin{enumerate}
    \item The purpose of~\autoref{chap:foundations} (chapter: Models of computation...) is to check in what programming paradigm/computation model,
    it will be the easiest for us to find characterizations. If imperative languages are hard to reason about, maybe consider functional
    languages?
    Also, if computational classes for Turing machines are hard to capture, maybe classes of complexity
    e.g. for lambda terms or for games (not examined here) will be easier to capture?
    \item The purpose of~\autoref{chap:formalized-semantics} is to examine reasoning
    about turing machines straight away, without any characterizations, in Coq. It is way too much work!
    \item In~\autoref{chap:descriptive-complexity} we study languages (logics) for decisional problems
        purely in terms of how complex is the specification of the problem. This gives us
        some characterizations of decisive complexity classes, and we can also
        define functions by bit-graphs and asking "is k-th bit of output f(x) 0 or 1?" repeatedly.
    \item The purpose of~\autoref{chap:reductions} is to find out if we can find language for polytime functions
    by making language for logspace reductions, then adding an oracle for decisional poly-time complete problem.
    We introduce functional complexity classes, which are crucial for our considerations.
    Then, going stronger, if we can have a language for FNP from FP + oracle for NP-complete problem.
    (answer turns out to be NO, as examined in section about TFNP). By the way, \(\complexity{FP}^{\complexity{NP}}\) is
    exactly what we would get this way, and this is a well-studied complexity class.
    And going weaker, if we can have language for FL from L-complete problem and circuit reductions.
    We leave this problem out, and only study circuit reductions/uniformity in appendix.
    We proceed to try find FL characterization right away in Linear Logic (Ugo Dal Lago IntML)
    and in Recursion Theory (Neergaard functional language).
    \item In~\autoref{chap:recursion-theory}, we study simple and cool function algebras
        that capture FL, and FP. Neergaard implemented a programming language for FL.
    \item In~\autoref{chap:linear-types}, we study Ugo Dal Lago's linear-types programming
        language that captures FL and FNL. Briefly! Because introducing linear types is too
        much overhead
    \item In~\autoref{chap:bounded-arithmetic}, we study my contribution!


\end{enumerate}

% - a program documented to perform some computation and return a result should not run into an
%   infinite loop
% - a program implementing an O(n)-time algorithm, and documented to execute in O(n) should not
%   need O(n^2) time to run by an accident in the implementation.
% - thoughtfully written (i.e. "clean") code should convince the user reading it that
%   it does what it is documented to. One way this is typically done is including parts of proof
%   of correctness in the documentation. Another way is declaring a function to have a particular type
%   and ensuring the user can quickly verify the implementation type-checks.




% \section{The full picture}
% States of the process of computation are dots. Computation is arrows between the dots.
% Since computation is sequential (even parallel programs have some intertwine, which is sequential),
% this is a linear graph. What programmer does is describe the arrows.
% The whole graph has bilions of computational steps, which we can't create nor verify.
% Yet, we want to reason about it.
% We want to also be able to construct data, e.g. the input.
% Verification checker has to confirm that if a precondition holds in state S before computation,
% then it also holds for F(S), which is state after computation. F is the semantics
% of some programming language function, so we need to have one functional symbol
% for every possible state function describable.

% The weaker the type system, and the more complicated the function, the less likely
% it is that it will be able to solve the tautology (by automated theorem proving).

% In functional languages, the syntax to describe data and functions is the same:
% lambda terms. Verification has to be supplied by the user as types.

% The interpreter is essentialy a proof that for every state, precisely one consecutive state
% of computation exists.


% # Introduction
% This thesis investigates the problem of certifying computational complexity of standard computer algorithms. The most intuitive solution to it is to formalize a standard computational model (e.g. Turing machines or lambda calculus) and its notion of computational complexity in a proof assistant such as Rocq or Lean. Then, implement the algorithm in such a formalization and prove that it will e.g. execute in polynomial time. This, however, proves to be extremely difficult. The proofs from the area of computational complexity tend to be very "hand-wavy" and making them formal is orders of magnitude more involved than formalizing other areas of mathematics [forster:LIPIcs.CSL.2025.3].
% As of September 2025, no feasible way of doing that on scale has been discovered.

% A promising approach is to first give an “on-paper” proof that the functions in a complexity class are equivalent to the semantics of a specially designed programming language. Then, instead of repeatedly checking complexity proofs for each algorithm, we can just define the algorithms in this language. That way, we only need to manually verify the interpreter once, and afterwards we can let the interpreter automatically check whether any given program is valid.

% This thesis investigates approaches to designing programming languages whose expressiveness is precisely aligned with a target computational complexity class. In such languages, every program would, by construction, operate within the given class, and conversely, any function or problem in that class would be expressible and implementable in the language.

% To illustrate the challenge we are addressing, consider the task of proving that binary multiplication belongs to LOGSPACE. 
% A common way to do it is to first argue that if we show a program that does it using only a finite number of variables, each of which of linear size (e.g. a pointer to the input), then the computation obviously uses only logarithmic amount of memory.
% However, this description is fragile: for instance, simply incrementing a variable in a `for` loop can exceed the LOGSPACE bound. In this work, we investigate more reliable characterizations.

% The ultimate goal of this thesis is to design a practical hierarchy of programming languages that precisely captures resource-bounded computations - for example, languages that express exactly the class of algorithms running in $\mathcal{O}(n^2)$ time or $\mathcal{O}(n)$ space. In the chapters that follow, we explore which restrictions of this kind are feasible, and which are not.

% The structure of this work is as follows:  
% - Chapter 1 reviews open sub-directions that remain unexplored, including descriptive complexity
% - Chapter 2 introduces Implicit Computational Complexity (ICC).  
% - Chapter 3 presents the Curry–Howard approach to ICC, focusing on IntML.  
% - Chapter 4 explores the recursion-theoretic approach, focusing on Neergaard's BC.  
% - Chapter 5 discusses the logical approach, drawing on my work for AITP and at INRIA.  

% Among these, only the logical approach has proven scalable. The others, after extensive investigation, appear unlikely to yield systems that are practical in use.

% \section{Requirements on the product: relation between syntax, semantics, and the interpreter complexity}
% ## Some obvious and obviously impractical approaches
% - The obvious approach: LOOP language.  
% problem: it is PRA. it is not practical.

% - Another obvious approach is: python + polynomial expressing max  
% number of steps. Problem: semantics impossible to reason about.

% - another obvious approach: "natural number coding nth program of a language
% having these properties". problem: syntax might be undecidable! won't write an
% interpreter.

% - another approach: only use Nat type and grzegorczyk hierarchy. problem: ?