\chapter{Linear types}
\label{chap:linear-types}

Linear logic can be thought of not as true facts we can reason upon or deduce,
but as resources that we can obtain and utilize (sometimes, destructively).


suppose that we have a web server. clients come to us and ask for a resource of type `b`.
we don't have it yet, but we have a function `a -> b`, and there is a small chance that
one client will send an erroneous request, with a valid object of type $a$ in it.
after this moment, we will just call our function, and send the b obtained to all clients.

gamma |- alpha, alpha->beta -> gamma|- b.

now, what if we have a bakery and the erroneous client give us a cake instead of buying it?
logically, the naive approach would be to 
we will be able to satisfy one clinet, but not the whole queue. yet, traditionally in logic we
don't have a way to 


What if we could encode in the type system that a function can only read an argument once?
Or that if you call a function A -> B on argument of type A, then you have access to an element
of type B, but lose the access to the original argument A (goes out of scope)?
Consider such a semantics of computer program:
- (contraction) once you use a variable, it goes out of scope
- (weakening) function is incorrect if at the end of it, some variable is still in scope (was unused)

This allows us to reason about resource usage in programs.

This idea is studied by the field of linear type systems.


A popular way to think of typed programs is to
think of an object of type $a -> b$ as a method to 
transform objects of type a to objects of type b.
so, if you obtain something of type $a$ (so, the type a is nonempty),
and something of type $a -> b$, then you can also obtain something of type $b$.


\section{Linear logic}
% perhaps take intro from this: https://theses.hal.science/tel-01123737v1/file/2015ENSL0981.pdf

Linear type systems are fully inspired by substructural logics.
They consider changing contraction and weakening rule, but keep exchange rule.

The formal bridge between the theories of linear types and the different kinds of linear logics is the Curry--Howard correspondence
(also known as propositions as types, or proofs as programs).
Extensive literature exists in this area, also known as the Curry--Howard correspondence. A good introduction to it is a book by S\o{}rensen and Urzyczyn: [@10.5555/1197021].

The resource interpretation is also there.

\section{Linear types and resources}

In intuitionistic logic and the simply typed $\lambda$-calculus, assumptions in the context $\Gamma$ can be freely duplicated (contraction) or ignored (weakening). This corresponds to programs that can copy or discard variables arbitrarily.

\textbf{Linear logic}, introduced by Girard, restricts these structural rules. In the corresponding $\lambda$-calculus, each variable must be used \emph{exactly once}. This leads to \textbf{linear types}, where values are treated as \emph{resources}:
\begin{itemize}[nosep]
  \item A value must be consumed once (no weakening).
  \item A value cannot be duplicated (no contraction).
  \item The order of usage does not matter (exchange is allowed).
\end{itemize}

Thus, linear types provide a fine-grained way to model computation where resources (such as memory cells, channels, or tokens) cannot be copied or discarded at will. This perspective opens the door to implicit control of computational complexity, since unrestricted duplication of resources is closely related to uncontrolled growth in computation.

\section{Modern results in Implicit Computational Complexity}


Bang and paragraph are parts of lambda term syntax. The theorem then is that such a term,
ignoring types, normalizes in polynomial number of beta steps?


In 2013, Dal Lago and Sch\"opp introduced \textbf{IntML}, a functional programming language with a linear type system that characterizes \complexity{FLOGSPACE} \cite{DALLAGO2016150}. This marked a significant milestone for Implicit Computational Complexity (ICC). An implementation of IntML is available on GitHub\footnote{\url{https://github.com/uelis/IntML}. Following my private communication with the authors, a permissive license was added to the repository, as it was not included originally.}, and to the best of my knowledge it remains the only language within the linear-logic branch of ICC that has both a working implementation and some potential for (academic) practical use.

Despite this achievement, IntML's complex typing rules make it difficult to translate most standard imperative algorithms into the language without substantial modification. While, in principle, the language could serve as a platform for reimplementing well-known algorithms within this new paradigm, the steep learning curve creates a significant barrier to adoption. As a result, it is unlikely to become a convenient tool for algorithm designers.

For these reasons, we decided not to pursue IntML further and not to focus on linear type systems in this work. Instead, we turn to another language discussed in Section~\ref{chap:icc-recursion-theory}.

\section{Support for linear types in mainstream programming languages}
Haskell has some. Rust also. Idris 2 has some. F*, Q*. quantum programming uses that a lot!