\chapter{Implicit Computational Complexity: recursion-theoretic approach}
\label{chap:recursion-theory}
Implicit computational complexity (ICC) studies how to guarantee resource bounds
without appealing to external machine models.
Instead of analysing running time or space after the fact, ICC designs
languages and recursion schemes whose syntactic constraints ensure that every
definable function belongs to a chosen complexity class.
The aim is a principled foundation for programming languages that ``build in''
complexity guarantees by construction.
In this chapter we focus on techniques from recursion theory that were successfully
utilized in this field to characterize complexity classes.

As discussed in~\ref{sec:classes-of-interest}, we will primarily focus on characterizations of L and P.
Characterizations we are interested in are described mostly in~\ref{sec:icc}. All of the historical
context of the field needs to also be addressed to describe why we were unsuccessful in designing a programming
language based on ideas from these papers. For a broad literature survey, see~\cite{bloch1994function}.

\section{Origins of recursion theory}
While not the primary focus of this work, the field of recursion theory developed concepts
that later became foundational for ICC\@. An important formal system studied there is \emph{primitive recursion}.

\begin{definition}[Primitive recursive functions]
\label{def:primitive-recursive}
\(\complexity{PR}\) is the smallest class of functions containing \(\text{(i)}\)--\(\text{(iii)}\) and closed under \(\text{(iv)}\), \(\text{(v)}\).
\begin{enumerate}[label=(\roman*)]
\item \textbf{(Constants)} For every \(n\in\mathbb{N}\) and \(k\ge 0\), the \(k\)-ary constant function
      \(c_{n}^{(k)}(\vec x)=n\).
\item \textbf{(Successor)} \(S(x)=x+1\).
\item \textbf{(Projections)} For \(k\ge 1\) and \(1\le i\le k\),
      \(\pi_i^{(k)}(x_1,\dots,x_k)=x_i\).
\item[(iv)] \textbf{(Composition)} If \(h:\mathbb{N}^m\to\mathbb{N}\) and
      \(g_1,\dots,g_m:\mathbb{N}^k\to\mathbb{N}\) are in \(\complexity{PR}\), then
      \(f(\vec x)=h\big(g_1(\vec x),\dots,g_m(\vec x)\big)\) is in \(\complexity{PR}\).
\item[(v)] \textbf{(Primitive recursion)} If \(g:\mathbb{N}^k\to\mathbb{N}\) and
      \(h:\mathbb{N}^{k+2}\to\mathbb{N}\) are in \(\complexity{PR}\), then the unique
      \(f:\mathbb{N}^{k+1}\to\mathbb{N}\) is in \(\complexity{PR}\) with:
      \[
      f(0,\vec x)=g(\vec x),\qquad
      f(S(y),\vec x)=h\big(y,\,f(y,\vec x),\,\vec x\big).
      \]

\end{enumerate}
\end{definition}

\begin{example}[Addition]
Define \(\mathrm{Add}:\mathbb{N}^2\to\mathbb{N}\) by primitive recursion:
\[
\mathrm{Add}(0,y)=y, \qquad
\mathrm{Add}(S(x),y)=S\big(\mathrm{Add}(x,y)\big).
\]
\end{example}

Interestingly, in~\cite{10.1145/800196.806014} it has been shown that the functions definable in a particular imperative
programming language are precisely the primitive recursive functions.

\begin{definition}[LOOP language]
Let \(\mathrm{Var}=\{x_0,x_1,x_2,\dots\}\).
LOOP programs are generated by the grammar
\[
\begin{aligned}
P ::=~& x_i := 0
\;\mid\; x_i := x_i + 1
\;\mid\; P \,;\, P
\;\mid\; \texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END},
\end{aligned}
\]
where \(x_i\in\mathrm{Var}\).

\noindent
We assume standard semantics, with a remark that \(\texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END}\) repeats \(P\) exactly as many times as the value stored in \(x_i\) \emph{at loop entry} (changes to \(x_i\) inside \(P\) do not change the iteration count).
\end{definition}

\begin{theorem}[\texttt{LOOP} captures precisely \complexity{PR}]
\label{thm:loop-captures-pr}
      TODO: make statement precise, perhaps based on https://www.cs.cornell.edu/courses/cs6110/2012sp/MeyerAndRitchie-67.pdf
\end{theorem}

This simple connection actually satisfies our criteria of a `programming language capturing a complexity class', as
the \(\texttt{LOOP}\) language captures exactly \(\complexity{PR}\)\footnote{As recognized in \url{https://complexityzoo.net/Complexity_Zoo:P}.}, the class of primitive recursive functions.
Moreover, we can even stratify the primitive recursive functions into a hierarchy like in~\cite{Grzegorczyk1953}.

Historically, the origins of primitive recursion can be traced back to~\cite{Grassmann1861} and~\cite{Dedekind1888},
but the class was probably first considered as the primary object of study in~\cite{Skolem1923-vanHeijenoort}.
For the details of the historical origins, consult~\cite{Adams2011}.

\section{Characterizations not easily adjustable for a programming language}
Before the seminal works that founded the field of Implicit Complexity, many characterizations
of complexity classes had been known already. All of them suffered at least one of the two problems:
either it only characterized a class of relations in a given complexity (as opposed to functions),
or the characterization wasn't purely syntactic. We will refer to the latter of beign ``explicit''
instead of ``implicit''.

\subsection{Characterizations of classes of relations}
Characterizations of classes of relations, such as \complexity{P} (as opposed to \complexity{FP}),
are not of interest to us because they don't generalize at all to a programming language
allowing to write functions with output. Nevertheless, we investigated the concepts used
there and describe some of them briefly in this subsection.

Polynomial-time relations have been characterized without explicit
size bounds in~\cite{doi:10.1137/0216051}.
In~\cite{COMPTON1990241}, uniform \(\complexityi{NC}{1}\) was characterized,
and in~\cite{ALLEN19911} uniform \(\complexity{NC}\), though their definitions
still concealed polynomial bounds and targeted relations instead of functions.

In more modern works, decisive complexity classes have been successfully characterized in~\cite{JONES1999151} by a fragment of Lisp in~\(\complexity{L}\) and
\(\complexity{P}\). The same concept has been extended to account for
for nondeterminism in~\cite{10.1007/11784180_8}.

The authors of~\cite{kristiansenvoda2005} investigated both imperative
and functional programming languages whose fragments yield hierarchies containing \emph{decisional} \complexity{L},
\complexity{LINSPACE}, \complexity{P}, and \complexity{PSPACE}.
Related contributions include~\cite{kristiansen2005neat} and~\cite{Oitavem+2010+355+362}.

\subsection{Explicit characterizations}
\label{subsec:explicit}
If a characterization of a complexity class is not purely syntactic, i.e.\ it needs a proof of some
additional property besides the function description, it becomes practically impossible to
use it as foundation of a practical programming language --- it becomes undecidable~\footnote{Nowadays, proof
assistants such as Rocq and Lean could be used to verify a user-provided proof, but this goes out of
scope of a \emph{programming language}.} if
a given function description is in the programming language at all. Nevertheless, these concepts
have been very important for the field and we shall discuss some of them in this subsection.

An example of such characterization is the Cobham's famous characterization
of polynomial-time functions, using the recursion scheme defined below in the style of~\cite{Tourlakis2022Computability}.
\begin{definition}
\label{def:bounded-binary-primitive-recursion}
A function \(f\) is defined from functions \(g\), \(h_0\), \(h_1\), and \(s\) by \emph{bounded primitive recursion on binary notation}
if, for every \(\vec x\) and \(y\in\mathbb{N}\),
\begin{align*}
f(\vec x, 0)      &= g(\vec x),\\
f(\vec x, S_0(y)) &= h_0\big(\vec x, y, f(\vec x, y)\big),\\
f(\vec x, S_1(y)) &= h_1\big(\vec x, y, f(\vec x, y)\big),
\end{align*}
and moreover \(f(\vec x, y) \le s(\vec x, y)\).
Here \(S_0(y)=2y\) and \(S_1(y)=2y+1\) append a binary digit to \(y\).
% Writing \(y0\) (resp.\ \(y1\)) for the natural number whose binary expansion is that of \(y\)
% followed by \(0\) (resp.\ \(1\)), the unfolding behaves like ordinary primitive recursion on binary notation while respecting the bound:
% \begin{align*}
% f(\vec x, 0)  &= g(\vec x) \le s(\vec x, 0),\\
% f(\vec x, 1)  &= h_1\big(\vec x, 0, f(\vec x, 0)\big) \le s(\vec x, 1),\\
% f(\vec x, 10) &= h_0\big(\vec x, 1, f(\vec x, 1)\big) \le s(\vec x, 10),\\
% f(\vec x, 11) &= h_1\big(\vec x, 1, f(\vec x, 1)\big) \le s(\vec x, 11),\;\dots
% \end{align*}
% An analogous construction can be formulated for any radix \(n \ge 2\).
\end{definition}
\begin{definition}[Cobham's algebra for \complexity{FP}]
\label{def:cobham}
The class of polynomial-time computable functions is the smallest class \(\mathcal{C}\) of functions such that:
\begin{enumerate}[label=(\roman*)]
\item \(\mathcal{C}\) contains the initial functions (as in~\ref{def:primitive-recursive}: constants, successor, projections), the~binary successor functions \(S_0(x)=2x\) and \(S_1(x)=2x+1\), and the weak exponential \((x,y)\mapsto x^{\lvert y\rvert}\).
\item \(\mathcal{C}\) is closed under composition.
\item \(\mathcal{C}\) is closed under bounded primitive recursion on binary notation as in Definition~\ref{def:bounded-binary-primitive-recursion}.
\end{enumerate}
\end{definition}

This formulation, due to Cobham~\cite{Cobham1964-COBTIC}, hides the polynomial bounds that are explicit in other
presentations. The recursion parameter is the binary representation of the argument, so a definition of~\(f(\vec x,y)\)
unfolds only \(\mathcal{O}(|y|)\) many steps, which is polynomial in the input size.
Moreover, the side condition \(f(\vec x,y)\le s(\vec x,y)\) forces every intermediate value to stay within
numbers of the form \(2^{p(|\vec x|,|y|)}\) for some polynomial \(p\), hence their binary length remains polynomially bounded.
When writing a function in this style, it is unclear how to certify that \(f(\vec x, y) \le s(\vec x, y)\) holds in
a way other than providing a full mathematical proof on the side.

Cobham has published this algebra in~\cite{Cobham1964-COBTIC}, suggesting that it captures \complexity{FP}.
A~proof of that is in~\cite[p. 175 / p. 186 of the PDF]{Odifreddi1999CRT2} and in~\cite[p. 608 / p. 625 of the PDF]{Tourlakis2022Computability}

Other explicit characterizations include the algebraic view of polynomial-time
functions~\cite{4568079} and, as mentioned above in~\ref{subsec:explicit}, uniform \(\complexityi{NC}{1}\) from~\cite{COMPTON1990241},
and uniform \(\complexity{NC}\) from~\cite{ALLEN19911}.

\section{Implicit Computational Complexity}
\label{sec:icc}
We can refine the connection given by~\ref{thm:loop-captures-pr}. As we will see, by carefully modifying the schemes of
recursion and composition, we can obtain characterizations of complexity classes such as \complexity{L} and \complexity{P}.

The modern study of ICC begins with two breakthroughs:
\cite{151625}~and~\cite{10.1007/BF01201998}
gave the first implicit characterisations of polynomial-time computable functions.
Since then, numerous classes have been captured implicitly; see, for
example, \cite{NIGGL201047}~and~\cite{10.1016/j.ic.2015.12.009}
for overviews of \(\complexity{FPTIME}\) and \(\complexity{FNC}\) characterisations.
However, the idea of Bellantoni and Cook seemed to best align with being the foundation
of a practical programming language. Hence, we decided to solely focus on it and its successors.

Accessible introductions to ICC include the three-part presentation~\cite{martini2006implicit1,martini2006implicit2,martini2006implicit3},
the talk~\cite{ronchi2019logic},
and a short overview~\cite{DalLago2012}.

\subsection{Bellantoni and Cook's algebra for \complexity{FP}}

Bellantoni and Cook introduced a function algebra \(\mathcal{B}\) whose key
innovation is the separation of arguments into \emph{normal} inputs (controlling
recursion depth) and \emph{safe} inputs (being passed around without
influencing that depth).
We write \(f(\vec{x};\vec{a})\), with normal inputs \(\vec{x}\) written to the left of the semicolon and safe inputs \(\vec{a}\) to the right .
The computation is performed on non-negative integers; proofs transfer to
general binary strings (e.g.\ starting with a zero)~\cite{10.1007/BF01201998}.
For an integer \(x\), let \(|x|\) denote its binary length
\(\lceil \log_2(x+1)\rceil\); for vectors use component-wise notation.

\begin{definition}[Bellantoni-Cook algebra]\label{def:bellantoni-cook}
The class \(\mathcal{B}\) is the smallest class of functions that contains the initial functions \(\text{(i)}\)--\(\text{(iv)}\) and is closed under \(\text{(vi)}\), \(\text{(vii)}\).
\begin{enumerate}[label=(\roman*)]
  \item \textbf{(Constant)} \(0(;)=0\).
  \item \textbf{(Projection)} \(\pi_j(x_1,\dots,x_m;\,x_{n+1},\dots,x_{n+m})=x_j\) for
        \(1\le j\le m+n\).
  \item \textbf{(Successors)} \(s_i(;a)=2a+i\) for \(i\in\{0,1\}\).
  \item \textbf{(Predecessor)} \(p(;0)=0\) and \(p(;ai)=a\).
  \item \textbf{(Conditional)}\[
        C(;a,b,c)=
        \begin{cases}
          b & \text{if } a\bmod 2 = 0,\\
          c & \text{otherwise.}
        \end{cases}
        \]
  \item \textbf{(Predicative recursion on notation)}\
        if \(g,h_0,h_1\in\mathcal{B}\), define the new \(f\) by
        \[
        f(0,\vec{x};\vec{a}) = g(\vec{x};\vec{a}),\qquad
        f(yi,\vec{x};\vec{a}) = h_i\bigl(y,\vec{x};\vec{a},f(y,\vec{x};\vec{a})\bigr),
        \]
        where \(i\in\{0,1\}\) and \(yi\) is \(y\) with bit \(i\) appended.
  \item \textbf{(Safe composition)}\
        if \(h,\vec{r},\vec{t}\in\mathcal{B}\) with each component of
        \(\vec{r}\) taking only normal arguments and each component of
        \(\vec{t}\) taking both normal and safe arguments, put
        \[
          f(\vec{x};\vec{a}) =
          h\bigl(\vec{r}(\vec{x};\,);\ \vec{t}(\vec{x};\vec{a})\bigr).
        \]
        Safe outputs never flow into a normal position.
\end{enumerate}

\paragraph{Intuition.}
Functions in \(\mathcal{B}\) can perform arbitrary polynomial-time computation
on their normal inputs.
Safe inputs may increase only by an additive constant, and recursive results
remain safe, so recursion depth cannot depend on previously computed values.
\end{definition}


Interestingly, in~\cite{10.1007/978-3-642-22863-6_11} the authors claim formalizing a~proof that a~version
of Bellantoni and Cook's algebra on bitstrings (as opposed to natural numbers here) captures precisely \complexity{FP}.
This is of interest to us, as initially it suggested that the authors have formalized the notion of an \complexity{FP}
function in a proof assistant and managed to implement some form of an interpreter. This is not the case, however, as
their proof is formalized proof that the class of functions in this algebra is the same as the class of functions
in Cobham's algebra, as defined in~\ref{def:cobham}~\footnote{Link to the source code: \url{https://github.com/davidnowak/bellantonicook}.}


% but: we know a similar picture. in proof theory, we have dag-like and tree-like proof systems,
% and the difference between them is than in dag-like proof systems we can name a fragment of proof
% and then refer to the name in many places. and we have a lot of results about probably
% exponential difference of size of proofs of propositional tautologies in these two


% \section{Logspace-Oriented Developments}
% Lind developed early logspace-oriented function algebras in 1973 and
% 1974~\cite{10.1145/1008293.1008295,lind1974logspace}, relying on explicit
% resource bounds.
% Bellantoni and Cook also investigated unary encodings suitable for
% logspace functions with small outputs~\cite{10.1007/BF01201998},
% and Jones explored tail-recursive read-only programs~\cite{JONES1999151}.
% Murawski and Ong introduced \(BC^{-}\) in 2000~\cite{murawski2000can},
% with further refinements in 2004~\cite{MURAWSKI2004197}, and
% Møller-Neergaard proved \(BC\varepsilon^{-} = \complexity{FL}\) in the same
% period.
% Hofmann summarised logspace languages in 2006~\cite{hofmann2006logspace},
% and Schöpp traced the history of logspace characterisations~\cite{schoepp2006spaceefficiency}.

% The original \(BC\text{-}\varepsilon\) code has been ported from Moscow ML to
% SML/NJ and released under a compatible licence, alongside an unpublished note
% that clarifies the original presentation.\footnote{\url{https://github.com/ruplet/neergaard-logspace-characterization}}
% The accompanying Haskell formalisation reproduces key examples from
% Neergaard's paper; one correction shows that the published definition of
% \(\mathsf{shiftR}\) swaps its arguments.
% The proof of this fact appears in \texttt{thesis-tex/main.tex}.

% \begin{verbatim}
% identity :: Func
% identity = Proj 1 0 1

% oneNormalToZero :: Func
% oneNormalToZero =
%   let g = ZeroFunc in
%   let h = Proj 1 1 2 in
%   let d = identity in
%   Recursion 0 0 g h h d d

% -- Proposition 1. Let m and n be numbers in binary. Right shift shiftR(m : n)
% -- of m by |n| and selection of bit |n| from m are definable in BCe-.

% -- shiftR(n : m) = m >> |n|
% shiftR :: Func
% shiftR =
%   let g = Proj 0 1 1 in
%   let d = oneNormalToZero in
%   -- h(timer : recursive) = tail(recursive)
%   let h = Composition 0 1 1 [1] Tail [] [Proj 1 1 2] in
%   Recursion 0 1 g h h d d
% \end{verbatim}
