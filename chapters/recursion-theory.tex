\chapter{Implicit Computational Complexity (ICC): recursion-theoretic approach}
\label{chap:recursion-theory}

As discussed in~\ref{sec:classes-of-interest}, we will primarily focus on characterizations of L and P.


\section{Origins of recursion theory}
While not the primary focus of this work, the field of recursion theory developed concepts
that later became foundational for ICC\@. An important formal system studied there is \emph{primitive recursion}.

\begin{definition}[Primitive recursive functions]
\(\complexity{PR}\) is the smallest class of functions containing \(\text{(i)}\)--\(\text{(iii)}\) and closed under \(\text{(iv)}\), \(\text{(v)}\).
\begin{enumerate}[label=(\roman*)]
\item \textbf{(Constants)} For every \(n\in\mathbb{N}\) and \(k\ge 0\), the \(k\)-ary constant function
      \(c_{n}^{(k)}(\vec x)=n\).
\item \textbf{(Successor)} \(S(x)=x+1\).
\item \textbf{(Projections)} For \(k\ge 1\) and \(1\le i\le k\),
      \(\pi_i^{(k)}(x_1,\dots,x_k)=x_i\).
\item[(iv)] \textbf{(Composition)} If \(h:\mathbb{N}^m\to\mathbb{N}\) and
      \(g_1,\dots,g_m:\mathbb{N}^k\to\mathbb{N}\) are in \(\complexity{PR}\), then
      \(f(\vec x)=h\big(g_1(\vec x),\dots,g_m(\vec x)\big)\) is in \(\complexity{PR}\).
\item[(v)] \textbf{(Primitive recursion)} If \(g:\mathbb{N}^k\to\mathbb{N}\) and
      \(h:\mathbb{N}^{k+2}\to\mathbb{N}\) are in \(\complexity{PR}\), then the unique
      \(f:\mathbb{N}^{k+1}\to\mathbb{N}\) is in \(\complexity{PR}\) with:
      \[
      f(0,\vec x)=g(\vec x),\qquad
      f(S(y),\vec x)=h\big(y,\,f(y,\vec x),\,\vec x\big).
      \]

\end{enumerate}
\end{definition}

\begin{example}[Addition]
Define \(\mathrm{Add}:\mathbb{N}^2\to\mathbb{N}\) by primitive recursion:
\[
\mathrm{Add}(0,y)=y, \qquad
\mathrm{Add}(S(x),y)=S\big(\mathrm{Add}(x,y)\big).
\]
\end{example}


\begin{definition}[LOOP language]
Let \(\mathrm{Var}=\{x_0,x_1,x_2,\dots\}\).
LOOP programs are generated by the grammar
\[
\begin{aligned}
P ::=~& x_i := 0
\;\mid\; x_i := x_i + 1
\;\mid\; P \,;\, P
\;\mid\; \texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END},
\end{aligned}
\]
where \(x_i\in\mathrm{Var}\).

\noindent
We assume standard semantics, with a remark that \(\texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END}\) repeats \(P\) exactly as many times as the value stored in \(x_i\) \emph{at loop entry} (changes to \(x_i\) inside \(P\) do not change the iteration count).
\end{definition}

Interestingly, in~\cite{10.1145/800196.806014} it has been shown that the functions definable by LOOP programs
are precisely the primitive recursive functions.
This simple example actually satisfies our criteria of a `programming language capturing a complexity class', as
the LOOP language captures exactly the primitive recursive functions\footnote{As recognized in \url{https://complexityzoo.net/Complexity_Zoo:P}.}.
Moreover, we can even stratify the primitive recursive functions into a hierarchy like in~\cite{Grzegorczyk1953}.


Historically, the origins of primitive recursion can be traced back to~\cite{Grassmann1861} and~\cite{Dedekind1888},
but the class was probably first considered as the primary object of study in~\cite{Skolem1923-vanHeijenoort}.
For the details of the historical origins, consult~\cite{Adams2011}.

\section{Implicit Computational Complexity}

% \subsection{What is Implicit Computational Complexity?}
% Implicit computational complexity (ICC) studies how to guarantee resource bounds
% without appealing to external machine models.
% Instead of analysing running time or space after the fact, ICC designs
% languages and recursion schemes whose syntactic constraints ensure that every
% definable function belongs to a chosen complexity class.
% The aim is a principled foundation for programming languages that ``build in''
% complexity guarantees by construction.
% Techniques from proof theory, recursion theory, and linear logic play prominent
% roles in this development.

% ICC can be seen as the proof-theoretic analogue of descriptive complexity.
% While descriptive complexity classifies decision problems through logical
% definability, ICC approaches complexity from within programming languages and
% type systems, enforcing bounds through their typing and recursion disciplines.

% Two prominent ICC traditions illustrate this idea.
% One investigates typed \(\lambda\)-calculi, often inspired by linear logic;
% this thread is discussed in the chapter on linear logic.
% The other starts with basic functions on binary strings (e.g. \( \mathsf{append}_0(x) \),
% \( \mathsf{append}_1(x) \), \( \mathsf{pop}(x) \), \( \mathsf{empty}() \))
% and studies the classes generated by closing under composition and recursion
% subject to carefully crafted restrictions.
% This recursion-theoretic viewpoint is the focus of the remainder of the chapter.

% \subsection{History of the Field}
% The modern study of ICC begins with back-to-back breakthroughs:
% Leivant in 1991~\cite{151625} and Bellantoni-Cook in 1992~\cite{10.1007/BF01201998}
% gave the first implicit characterisations of polynomial-time computable functions.

% Earlier work hinted at the programme.
% Immerman characterised polynomial-time relations in 1987 without explicit
% size bounds~\cite{doi:10.1137/0216051}.
% Compton and LaFlamme~\cite{COMPTON1990241} captured uniform \(\complexityi{NC}{1}\),
% and Allen~\cite{ALLEN19911} uniform \(\complexity{NC}\), though their definitions
% still concealed polynomial bounds and targeted relations instead of functions.
% Other precursors include Gurevich's algebraic view of polynomial-time
% functions~\cite{4568079} and Cobham's seminal 1964 characterisation of
% \(\complexity{FP}\)~\cite{Cobham1964-COBTIC}, both of which retained explicit
% polynomial constraints.
% For a broader literature survey, see Bloch~\cite{bloch1994function}.

% Since the 1990s numerous classes have been captured implicitly; see, for
% example, Niggl~\cite{NIGGL201047} and Oitavem et al.~\cite{10.1016/j.ic.2015.12.009}
% for overviews of \(\complexity{FPTIME}\) and \(\complexity{FNC}\) characterisations.
% Jones connected fragments of Lisp to the decisive classes \(\complexity{L}\) and
% \(\complexity{P}\)~\cite{JONES1999151}; Bonfante extended the analysis~\cite{10.1007/11784180_8};
% Kristiansen and Voda~\cite{kristiansenvoda2005} investigated both imperative
% and functional languages whose fragments yield hierarchies containing logspace,
% linear space, polynomial time, and polynomial space.
% Related contributions include work by Kristiansen~\cite{kristiansen2005neat},
% Oitavem~\cite{Oitavem+2010+355+362}, and many others.
% Because this thesis concentrates on \(\complexity{FPTIME}\) and \(\complexity{FLOGSPACE}\),
% these classes receive focused attention below.

% Accessible introductions to ICC include the three-part presentation by
% Simone Martini~\cite{martini2006implicit1,martini2006implicit2,martini2006implicit3},
% Simona Ronchi Della Rocca's 2019 talk~\cite{ronchi2019logic},
% and Ugo Dal Lago's short overview~\cite{DalLago2012}.

% \section{Recursion-Theoretic Approach}
% \label{sec:recursion-theory-approach}
% The recursion-theoretic branch of ICC avoids simulating Turing machines.
% Instead, it controls complexity directly by limiting how new functions arise
% from simpler ones.

% Classical recursion theory builds all computable functions from basic ones
% (zero, successor, projections) by closing under composition and recursion.
% Restricting the recursion principles offers refined control: only certain
% recursion patterns are allowed, and the resulting function algebra coincides
% with a target complexity class.

% Primitive recursion and the Grzegorczyk hierarchy already stratify total
% functions by growth rate, yet they do not align neatly with standard classes
% such as \(\complexity{P}\) or \(\complexity{L}\).
% The challenge is to refine recursion principles so that they correspond exactly
% to natural complexity classes.

% \subsection{Bellantoni and Cook's Safe Recursion for \texorpdfstring{\(\complexity{FP}\)}{\complexity{FP}} and \texorpdfstring{\(\complexity{FL}\)}{\complexity{FL}}}
% Bellantoni and Cook introduced a function algebra \(\mathcal{B}\) whose key
% innovation is the separation of arguments into \emph{normal} inputs (written to
% the left of a semicolon) and \emph{safe} inputs (to the right).
% We write \(f(\vec{x};\vec{a})\), with normal inputs \(\vec{x}\) controlling
% recursion depth and safe inputs \(\vec{a}\) being passed around without
% influencing that depth.
% The computation is performed on non-negative integers; proofs transfer to
% binary strings~\cite{10.1007/BF01201998}.
% For an integer \(x\), let \(|x|\) denote its binary length
% \(\lceil \log_2(x+1)\rceil\); for vectors use component-wise notation.

% \subsubsection{Initial Functions}
% \(\mathcal{B}\) is the smallest class containing the following base functions:
% \begin{enumerate}
%   \item \textbf{Zero}: the nullary function \(0\).
%   \item \textbf{Projections}: for \(n,m \geq 0\) and \(1 \leq j \leq n+m\),
%   \[
%     \pi^{n,m}_j(x_1,\dots,x_n;\,x_{n+1},\dots,x_{n+m}) = x_j.
%   \]
%   \item \textbf{Successors}: appending a bit for \(i \in \{0,1\}\),
%   \( s_i(\,;a) = 2a + i \).
%   \item \textbf{Predecessor}: deleting the last bit,
%   \( p(\,;0)=0 \) and \( p(\,;ai)=a \) for \(i\in\{0,1\}\).
%   \item \textbf{Conditional on the last bit}:
%   \[
%     C(\,;a,b,c) =
%     \begin{cases}
%       b & \text{if } a \bmod 2 = 0,\\
%       c & \text{otherwise.}
%     \end{cases}
%   \]
% \end{enumerate}

% \subsubsection{Closure Principles}
% \(\mathcal{B}\) is closed under:
% \begin{enumerate}
%   \item \textbf{Predicative recursion on notation (PRN)}:
%   given \(g,h_0,h_1 \in \mathcal{B}\), define \(f\) by
%   \[
%   \begin{aligned}
%     f(0,\vec{x};\vec{a})   &= g(\vec{x};\vec{a}),\\
%     f(yi,\vec{x};\vec{a}) &= h_i\!\big(y,\vec{x};\vec{a},f(y,\vec{x};\vec{a})\big),
%   \end{aligned}
%   \]
%   where \(i\in\{0,1\}\) and \(yi\) denotes appending bit \(i\) to \(y\).
%   The recursive value enters only a safe argument position, preventing it from
%   later becoming a normal input.
%   \item \textbf{Safe composition (SC)}:
%   for \(h,\vec{r},\vec{t} \in \mathcal{B}\),
%   \[
%     f(\vec{x};\vec{a}) = h\big(\vec{r}(\vec{x};\,);\ \vec{t}(\vec{x};\vec{a})\big).
%   \]
%   The functions \(\vec{r}\) may depend only on normal inputs, whereas
%   \(\vec{t}\) may depend on both; safe outputs never flow into normal positions.
% \end{enumerate}

% \paragraph{Intuition.}
% Functions in \(\mathcal{B}\) can perform arbitrary polynomial-time computation
% on their normal inputs.
% Safe inputs may increase only by an additive constant, and recursive results
% remain safe, so recursion depth cannot depend on previously computed values.
% This predicative discipline ensures two directions:
% every function definable in \(\mathcal{B}\) is computable in polynomial time,
% and every polynomial-time function can be expressed using only normal arguments.

% \subsection{Characterisation of Polynomial Time}
% The polynomial-time functions are exactly those members of \(\mathcal{B}\) whose
% signature contains only normal inputs.
% Duplicating safe arguments would allow super-polynomial growth, so their role is
% strictly controlled.

% \subsection{Neergaard's \(BC\text{-}\varepsilon\): Definition and Intuition}
% Neergaard's \(BC\text{-}\varepsilon\) algebra follows the Bellantoni--Cook
% separation of normal and safe arguments but adds an \emph{affine} restriction on
% safe data and works directly with binary strings.

% \paragraph{Setup.}
% \begin{itemize}
%   \item Numbers are words over \(\{0,1\}\); the empty word \(\varepsilon\) denotes \(0\).
%   \item Arguments split into normal and safe parts, written
%   \(f(x_1,\dots,x_m : y_1,\dots,y_n)\).
%   \item Safe arguments are affine: each may be used at most once.
%   \item Recursion is permitted only on normal arguments.
% \end{itemize}

% \paragraph{Definition.}
% \(BC\text{-}\varepsilon\) is the least set of functions over binary strings that
% contains the following base functions and is closed under safe affine
% composition and safe affine course-of-value recursion.
% \begin{enumerate}
%   \item \textbf{Base functions}: constant \(0(:)=\varepsilon\); predecessor
%     \(p(:\,\varepsilon)=\varepsilon\) and \(p(:\,yb)=y\); projections
%     \(\pi^{m,n}_j(x_1,\dots,x_m : x_{m+1},\dots,x_{m+n}) = x_j\);
%     successors \(s_0(:\,y)=y0\) and \(s_1(:\,y)=y1\); conditional on the last
%     bit selecting \(y_2\) when the first argument ends in \(1\).
%   \item \textbf{Safe affine composition}:
%     if \(f : N_2^{M,N} \to N_2\),
%     \(g_1,\dots,g_M : N_2^{m,0} \to N_2\), and
%     \(h_1,\dots,h_N\) each consume disjoint subsets of safe inputs, then
%     \[
%       (f \circ \langle g_1,\dots,g_M : h_1,\dots,h_N\rangle)(x : y)
%       = f\big(g_1(x:),\dots,g_M(x:) : h_1(x:\mathbf{y}^{\,1}),\dots\big),
%     \]
%     where the tuple \(y\) is partitioned so that each safe variable appears in
%     at most one block \(\mathbf{y}^{\,j}\).
%   \item \textbf{Safe affine course-of-value recursion}:
%     given \(g : N_2^{m,n}\to N_2\),
%     \(h_0,h_1 : N_2^{m+1,1}\to N_2\),
%     \(d_0,d_1 : N_2^{m+1,0}\to N_2\),
%     define \(f = \mathrm{rec}(g,h_0,\delta_0,h_1,\delta_1)\) by
%     \[
%       f(n,x:y) =
%       \begin{cases}
%         g(x:y), & n=\varepsilon,\\[4pt]
%         h_{b_1}\big(b_k\cdots b_2, x : f(b_k\cdots b_2+\delta, x:y)\big),
%         & n = b_k\cdots b_2 b_1,
%       \end{cases}
%     \]
%     where \(\delta = \bigl|d_{b_1}(b_k\cdots b_2, x:)\bigr|\).
% \end{enumerate}
% Notation follows the original presentation: nullary \(f\) abbreviates
% \(f \circ \langle : \rangle\), and \(\mathrm{rec}(g,h,\delta)\) stands for
% \(\mathrm{rec}(g,h,\delta,h,\delta)\).

% \paragraph{Intuition.}
% Affine use of safe inputs prevents duplication and thus uncontrolled growth,
% while normal inputs control recursion depth.
% Safe affine composition confines normal arguments to depend only on normal data,
% and course-of-value recursion can inspect earlier values via the offset terms,
% yet the recursive result always flows back into a safe position linearly.
% Removing the affine restriction recovers the original Bellantoni--Cook algebra.

% - koncepcja: różnica między algebrą BCeps- a BC jest taka, że BCeps- "wymaga"
%   re-obliczania podwyrażeń po zrobieniu na nich ifa. To jest insight za L neq P
  

% in neergaard's logic for logspace, we cannot use the result of computation after doing an `if` on the result.
% this 'affinity' seems to be the difference between algebra for \complexity{FL} and for \complexity{FP}.

% but: we know a similar picture. in proof theory, we have dag-like and tree-like proof systems,
% and the difference between them is than in dag-like proof systems we can name a fragment of proof
% and then refer to the name in many places. and we have a lot of results about probably
% exponential difference of size of proofs of propositional tautologies in these two


% \section{Cobham's Characterisation of \texorpdfstring{\(\complexity{FP}\)}{\complexity{FP}}}
% \label{sec:cobham-characterisation-stub}
% \textbf{Stub.} Detailed material on Cobham's function algebra for
% \(\complexity{FP}\) will be added once the supporting definitions are prepared.

% \section{Logspace-Oriented Developments}
% Lind developed early logspace-oriented function algebras in 1973 and
% 1974~\cite{10.1145/1008293.1008295,lind1974logspace}, relying on explicit
% resource bounds.
% Bellantoni and Cook also investigated unary encodings suitable for
% logspace functions with small outputs~\cite{10.1007/BF01201998},
% and Jones explored tail-recursive read-only programs~\cite{JONES1999151}.
% Murawski and Ong introduced \(BC^{-}\) in 2000~\cite{murawski2000can},
% with further refinements in 2004~\cite{MURAWSKI2004197}, and
% Møller-Neergaard proved \(BC\varepsilon^{-} = \complexity{FL}\) in the same
% period.
% Hofmann summarised logspace languages in 2006~\cite{hofmann2006logspace},
% and Schöpp traced the history of logspace characterisations~\cite{schoepp2006spaceefficiency}.

% The original \(BC\text{-}\varepsilon\) code has been ported from Moscow ML to
% SML/NJ and released under a compatible licence, alongside an unpublished note
% that clarifies the original presentation.\footnote{\url{https://github.com/ruplet/neergaard-logspace-characterization}}
% The accompanying Haskell formalisation reproduces key examples from
% Neergaard's paper; one correction shows that the published definition of
% \(\mathsf{shiftR}\) swaps its arguments.
% The proof of this fact appears in \texttt{thesis-tex/main.tex}.

% \begin{verbatim}
% identity :: Func
% identity = Proj 1 0 1

% oneNormalToZero :: Func
% oneNormalToZero =
%   let g = ZeroFunc in
%   let h = Proj 1 1 2 in
%   let d = identity in
%   Recursion 0 0 g h h d d

% -- Proposition 1. Let m and n be numbers in binary. Right shift shiftR(m : n)
% -- of m by |n| and selection of bit |n| from m are definable in BCe-.

% -- shiftR(n : m) = m >> |n|
% shiftR :: Func
% shiftR =
%   let g = Proj 0 1 1 in
%   let d = oneNormalToZero in
%   -- h(timer : recursive) = tail(recursive)
%   let h = Composition 0 1 1 [1] Tail [] [Proj 1 1 2] in
%   Recursion 0 1 g h h d d
% \end{verbatim}
