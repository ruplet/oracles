\chapter{Implicit Computational Complexity: recursion-theoretic approach}
\label{chap:recursion-theory}
Implicit computational complexity (ICC) studies how to guarantee resource bounds
without appealing to external machine models.
Instead of analysing running time or space after the fact, ICC designs
languages and recursion schemes whose syntactic constraints ensure that every
definable function belongs to a chosen complexity class.
The aim is a principled foundation for programming languages that ``build in''
complexity guarantees by construction.
In this chapter we focus on techniques from recursion theory that were successfully
utilized in this field to characterize complexity classes.

As discussed in~\ref{sec:classes-of-interest}, we will primarily focus on characterizations of L and P.
Characterizations we are interested in are described mostly in~\ref{sec:icc}. All of the historical
context of the field needs to also be addressed to describe why we were unsuccessful in designing a programming
language based on ideas from these papers. For a broad literature survey, see~\cite{bloch1994function}.

\section{Origins of recursion theory}
While not the primary focus of this work, the field of recursion theory developed concepts
that later became foundational for ICC\@. An important formal system studied there is \emph{primitive recursion}.

\begin{definition}[Primitive recursive functions]
\label{def:primitive-recursive}
\(\complexity{PR}\) is the smallest class of functions containing \(\text{(i)}\)--\(\text{(iii)}\) and closed under \(\text{(iv)}\), \(\text{(v)}\).
\begin{enumerate}[label=(\roman*)]
\item \textbf{(Constants)} For every \(n\in\mathbb{N}\) and \(k\ge 0\), the \(k\)-ary constant function
      \(c_{n}^{(k)}(\vec x)=n\).
\item \textbf{(Successor)} \(S(x)=x+1\).
\item \textbf{(Projections)} For \(k\ge 1\) and \(1\le i\le k\),
      \(\pi_i^{(k)}(x_1,\dots,x_k)=x_i\).
\item[(iv)] \textbf{(Composition)} If \(h:\mathbb{N}^m\to\mathbb{N}\) and
      \(g_1,\dots,g_m:\mathbb{N}^k\to\mathbb{N}\) are in \(\complexity{PR}\), then
      \(f(\vec x)=h\big(g_1(\vec x),\dots,g_m(\vec x)\big)\) is in \(\complexity{PR}\).
\item[(v)] \textbf{(Primitive recursion)} If \(g:\mathbb{N}^k\to\mathbb{N}\) and
      \(h:\mathbb{N}^{k+2}\to\mathbb{N}\) are in \(\complexity{PR}\), then the unique
      \(f:\mathbb{N}^{k+1}\to\mathbb{N}\) is in \(\complexity{PR}\) with:
      \[
      f(0,\vec x)=g(\vec x),\qquad
      f(S(y),\vec x)=h\big(y,\,f(y,\vec x),\,\vec x\big).
      \]

\end{enumerate}
\end{definition}

\begin{example}[Addition]
Define \(\mathrm{Add}:\mathbb{N}^2\to\mathbb{N}\) by primitive recursion:
\[
\mathrm{Add}(0,y)=y, \qquad
\mathrm{Add}(S(x),y)=S\big(\mathrm{Add}(x,y)\big).
\]
\end{example}

Interestingly, in~\cite{10.1145/800196.806014} it has been shown that the functions definable in a particular imperative
programming language are precisely the primitive recursive functions.

\begin{definition}[LOOP language]
Let \(\mathrm{Var}=\{x_0,x_1,x_2,\dots\}\).
LOOP programs are generated by the grammar
\[
\begin{aligned}
P ::=~& x_i := 0
\;\mid\; x_i := x_i + 1
\;\mid\; P \,;\, P
\;\mid\; \texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END},
\end{aligned}
\]
where \(x_i\in\mathrm{Var}\).

\noindent
We assume standard semantics, with a remark that \(\texttt{LOOP}~x_i~\texttt{DO}~P~\texttt{END}\) repeats \(P\) exactly as many times as the value stored in \(x_i\) \emph{at loop entry} (changes to \(x_i\) inside \(P\) do not change the iteration count).
\end{definition}

\begin{theorem}[\texttt{LOOP} captures precisely \complexity{PR}]
\label{thm:loop-captures-pr}
      TODO: make statement precise, perhaps based on https://www.cs.cornell.edu/courses/cs6110/2012sp/MeyerAndRitchie-67.pdf
\end{theorem}

This simple connection actually satisfies our criteria of a `programming language capturing a complexity class', as
the \(\texttt{LOOP}\) language captures exactly \(\complexity{PR}\)\footnote{As recognized in \url{https://complexityzoo.net/Complexity_Zoo:P}.}, the class of primitive recursive functions.
Moreover, we can even stratify the primitive recursive functions into a hierarchy like in~\cite{Grzegorczyk1953}.

Historically, the origins of primitive recursion can be traced back to~\cite{Grassmann1861} and~\cite{Dedekind1888},
but the class was probably first considered as the primary object of study in~\cite{Skolem1923-vanHeijenoort}.
For the details of the historical origins, consult~\cite{Adams2011}.

\section{Characterizations not easily adjustable for a programming language}
Before the seminal works that founded the field of Implicit Complexity, many characterizations
of complexity classes had been known already. All of them suffered at least one of the two problems:
either it only characterized a class of relations in a given complexity (as opposed to functions),
or the characterization wasn't purely syntactic. We will refer to the latter of beign ``explicit''
instead of ``implicit''.

\subsection{Characterizations of classes of relations}
Characterizations of classes of relations, such as \complexity{P} (as opposed to \complexity{FP}),
are not of interest to us because they don't generalize at all to a programming language
allowing to write functions with output. Nevertheless, we investigated the concepts used
there and describe some of them briefly in this subsection.

Polynomial-time relations have been characterized without explicit
size bounds in~\cite{doi:10.1137/0216051}.
In~\cite{COMPTON1990241}, uniform \(\complexityi{NC}{1}\) was characterized,
and in~\cite{ALLEN19911} uniform \(\complexity{NC}\), though their definitions
still concealed polynomial bounds and targeted relations instead of functions.

In more modern works, decisive complexity classes have been successfully characterized in~\cite{JONES1999151} by a fragment of Lisp in~\(\complexity{L}\) and
\(\complexity{P}\). The same concept has been extended to account for
for nondeterminism in~\cite{10.1007/11784180_8}.

The authors of~\cite{kristiansenvoda2005} investigated both imperative
and functional programming languages whose fragments yield hierarchies containing \emph{decisional} \complexity{L},
\complexity{LINSPACE}, \complexity{P}, and \complexity{PSPACE}.
Related contributions include~\cite{kristiansen2005neat} and~\cite{Oitavem+2010+355+362}.

\subsection{Explicit characterizations}
\label{subsec:explicit}
If a characterization of a complexity class is not purely syntactic, i.e.\ it needs a proof of some
additional property besides the function description, it becomes practically impossible to
use it as foundation of a practical programming language --- it becomes undecidable~\footnote{Nowadays, proof
assistants such as Rocq and Lean could be used to verify a user-provided proof, but this goes out of
scope of a \emph{programming language}.} if
a given function description is in the programming language at all. Nevertheless, these concepts
have been very important for the field and we shall discuss some of them in this subsection.

An example of such characterization is the Cobham's famous characterization
of polynomial-time functions, using the recursion scheme defined below in the style of~\cite{Tourlakis2022Computability}.
\begin{definition}
\label{def:bounded-binary-primitive-recursion}
A function \(f\) is defined from functions \(g\), \(h_0\), \(h_1\), and \(s\) by \emph{bounded primitive recursion on binary notation}
if, for every \(\vec x\) and \(y\in\mathbb{N}\),
\begin{align*}
f(\vec x, 0)      &= g(\vec x),\\
f(\vec x, S_0(y)) &= h_0\big(\vec x, y, f(\vec x, y)\big),\\
f(\vec x, S_1(y)) &= h_1\big(\vec x, y, f(\vec x, y)\big),
\end{align*}
and moreover \(f(\vec x, y) \le s(\vec x, y)\).
Here \(S_0(y)=2y\) and \(S_1(y)=2y+1\) append a binary digit to \(y\).
% Writing \(y0\) (resp.\ \(y1\)) for the natural number whose binary expansion is that of \(y\)
% followed by \(0\) (resp.\ \(1\)), the unfolding behaves like ordinary primitive recursion on binary notation while respecting the bound:
% \begin{align*}
% f(\vec x, 0)  &= g(\vec x) \le s(\vec x, 0),\\
% f(\vec x, 1)  &= h_1\big(\vec x, 0, f(\vec x, 0)\big) \le s(\vec x, 1),\\
% f(\vec x, 10) &= h_0\big(\vec x, 1, f(\vec x, 1)\big) \le s(\vec x, 10),\\
% f(\vec x, 11) &= h_1\big(\vec x, 1, f(\vec x, 1)\big) \le s(\vec x, 11),\;\dots
% \end{align*}
% An analogous construction can be formulated for any radix \(n \ge 2\).
\end{definition}
\begin{definition}[Cobham's algebra for \complexity{FP}]
\label{def:cobham}
The class of polynomial-time computable functions is the smallest class \(\mathcal{C}\) of functions such that:
\begin{enumerate}[label=(\roman*)]
\item \(\mathcal{C}\) contains the initial functions (as in~\ref{def:primitive-recursive}: constants, successor, projections), the~binary successor functions \(S_0(x)=2x\) and \(S_1(x)=2x+1\), and the weak exponential \((x,y)\mapsto x^{\lvert y\rvert}\).
\item \(\mathcal{C}\) is closed under composition.
\item \(\mathcal{C}\) is closed under bounded primitive recursion on binary notation as in Definition~\ref{def:bounded-binary-primitive-recursion}.
\end{enumerate}
\end{definition}

This formulation, due to Cobham~\cite{Cobham1964-COBTIC}, hides the polynomial bounds that are explicit in other
presentations. The recursion parameter is the binary representation of the argument, so a definition of~\(f(\vec x,y)\)
unfolds only \(\mathcal{O}(|y|)\) many steps, which is polynomial in the input size.
Moreover, the side condition \(f(\vec x,y)\le s(\vec x,y)\) forces every intermediate value to stay within
numbers of the form \(2^{p(|\vec x|,|y|)}\) for some polynomial \(p\), hence their binary length remains polynomially bounded.
When writing a function in this style, it is unclear how to certify that \(f(\vec x, y) \le s(\vec x, y)\) holds in
a way other than providing a full mathematical proof on the side.

Cobham has published this algebra in~\cite{Cobham1964-COBTIC}, suggesting that it captures \complexity{FP}.
A~proof of that is in~\cite[p. 175 / p. 186 of the PDF]{Odifreddi1999CRT2} and in~\cite[p. 608 / p. 625 of the PDF]{Tourlakis2022Computability}

Other explicit characterizations include the algebraic view of polynomial-time
functions~\cite{4568079} and, as mentioned above in~\ref{subsec:explicit}, uniform \(\complexityi{NC}{1}\) from~\cite{COMPTON1990241},
and uniform \(\complexity{NC}\) from~\cite{ALLEN19911}.

\section{Implicit Computational Complexity}
\label{sec:icc}
We can refine the connection given by~\ref{thm:loop-captures-pr}. As we will see, by carefully modifying the schemes of
recursion and composition, we can obtain characterizations of complexity classes such as \complexity{L} and \complexity{P}.

The modern study of ICC begins with two breakthroughs:
\cite{151625}~and~\cite{10.1007/BF01201998}
gave the first implicit characterisations of polynomial-time computable functions.
Since then, numerous classes have been captured implicitly; see, for
example, \cite{NIGGL201047}~and~\cite{10.1016/j.ic.2015.12.009}
for overviews of \(\complexity{FPTIME}\) and \(\complexity{FNC}\) characterisations.
However, the idea of Bellantoni and Cook seemed to best align with being the foundation
of a practical programming language. Hence, we decided to solely focus on it and its successors.

Accessible introductions to ICC include the three-part presentation~\cite{martini2006implicit1,martini2006implicit2,martini2006implicit3},
the talk~\cite{ronchi2019logic},
and a short overview~\cite{DalLago2012}.

\subsection{Bellantoni and Cook's algebra for \complexity{FP}}
% \subsection{Bellantoni and Cook's Safe Recursion for \texorpdfstring{\(\complexity{FP}\)}{\complexity{FP}} and \texorpdfstring{\(\complexity{FL}\)}{\complexity{FL}}}
% Bellantoni and Cook introduced a function algebra \(\mathcal{B}\) whose key
% innovation is the separation of arguments into \emph{normal} inputs (written to
% the left of a semicolon) and \emph{safe} inputs (to the right).
% We write \(f(\vec{x};\vec{a})\), with normal inputs \(\vec{x}\) controlling
% recursion depth and safe inputs \(\vec{a}\) being passed around without
% influencing that depth.
% The computation is performed on non-negative integers; proofs transfer to
% binary strings~\cite{10.1007/BF01201998}.
% For an integer \(x\), let \(|x|\) denote its binary length
% \(\lceil \log_2(x+1)\rceil\); for vectors use component-wise notation.

% \subsubsection{Initial Functions}
% \(\mathcal{B}\) is the smallest class containing the following base functions:
% \begin{enumerate}
%   \item \textbf{Zero}: the nullary function \(0\).
%   \item \textbf{Projections}: for \(n,m \geq 0\) and \(1 \leq j \leq n+m\),
%   \[
%     \pi^{n,m}_j(x_1,\dots,x_n;\,x_{n+1},\dots,x_{n+m}) = x_j.
%   \]
%   \item \textbf{Successors}: appending a bit for \(i \in \{0,1\}\),
%   \( s_i(\,;a) = 2a + i \).
%   \item \textbf{Predecessor}: deleting the last bit,
%   \( p(\,;0)=0 \) and \( p(\,;ai)=a \) for \(i\in\{0,1\}\).
%   \item \textbf{Conditional on the last bit}:
%   \[
%     C(\,;a,b,c) =
%     \begin{cases}
%       b & \text{if } a \bmod 2 = 0,\\
%       c & \text{otherwise.}
%     \end{cases}
%   \]
% \end{enumerate}

% \subsubsection{Closure Principles}
% \(\mathcal{B}\) is closed under:
% \begin{enumerate}
%   \item \textbf{Predicative recursion on notation (PRN)}:
%   given \(g,h_0,h_1 \in \mathcal{B}\), define \(f\) by
%   \[
%   \begin{aligned}
%     f(0,\vec{x};\vec{a})   &= g(\vec{x};\vec{a}),\\
%     f(yi,\vec{x};\vec{a}) &= h_i\!\big(y,\vec{x};\vec{a},f(y,\vec{x};\vec{a})\big),
%   \end{aligned}
%   \]
%   where \(i\in\{0,1\}\) and \(yi\) denotes appending bit \(i\) to \(y\).
%   The recursive value enters only a safe argument position, preventing it from
%   later becoming a normal input.
%   \item \textbf{Safe composition (SC)}:
%   for \(h,\vec{r},\vec{t} \in \mathcal{B}\),
%   \[
%     f(\vec{x};\vec{a}) = h\big(\vec{r}(\vec{x};\,);\ \vec{t}(\vec{x};\vec{a})\big).
%   \]
%   The functions \(\vec{r}\) may depend only on normal inputs, whereas
%   \(\vec{t}\) may depend on both; safe outputs never flow into normal positions.
% \end{enumerate}

% \paragraph{Intuition.}
% Functions in \(\mathcal{B}\) can perform arbitrary polynomial-time computation
% on their normal inputs.
% Safe inputs may increase only by an additive constant, and recursive results
% remain safe, so recursion depth cannot depend on previously computed values.
% This predicative discipline ensures two directions:
% every function definable in \(\mathcal{B}\) is computable in polynomial time,
% and every polynomial-time function can be expressed using only normal arguments.

% \subsection{Characterisation of Polynomial Time}
% The polynomial-time functions are exactly those members of \(\mathcal{B}\) whose
% signature contains only normal inputs.
% Duplicating safe arguments would allow super-polynomial growth, so their role is
% strictly controlled.



Interestingly, in~\cite{10.1007/978-3-642-22863-6_11} it has been formally verified that a version of Bellantoni and Cook's algebra on bitstrings (as opposed to natural numbers) corresponds precisely to the algebra of
Cobham, as defined in~\ref{def:cobham}~\footnote{Link to the source code: \url{https://github.com/davidnowak/bellantonicook}.}


% \subsection{Neergaard's \(BC\text{-}\varepsilon\): Definition and Intuition}
% Neergaard's \(BC\text{-}\varepsilon\) algebra follows the Bellantoni--Cook
% separation of normal and safe arguments but adds an \emph{affine} restriction on
% safe data and works directly with binary strings.

% \paragraph{Setup.}
% \begin{itemize}
%   \item Numbers are words over \(\{0,1\}\); the empty word \(\varepsilon\) denotes \(0\).
%   \item Arguments split into normal and safe parts, written
%   \(f(x_1,\dots,x_m : y_1,\dots,y_n)\).
%   \item Safe arguments are affine: each may be used at most once.
%   \item Recursion is permitted only on normal arguments.
% \end{itemize}

% \paragraph{Definition.}
% \(BC\text{-}\varepsilon\) is the least set of functions over binary strings that
% contains the following base functions and is closed under safe affine
% composition and safe affine course-of-value recursion.
% \begin{enumerate}
%   \item \textbf{Base functions}: constant \(0(:)=\varepsilon\); predecessor
%     \(p(:\,\varepsilon)=\varepsilon\) and \(p(:\,yb)=y\); projections
%     \(\pi^{m,n}_j(x_1,\dots,x_m : x_{m+1},\dots,x_{m+n}) = x_j\);
%     successors \(s_0(:\,y)=y0\) and \(s_1(:\,y)=y1\); conditional on the last
%     bit selecting \(y_2\) when the first argument ends in \(1\).
%   \item \textbf{Safe affine composition}:
%     if \(f : N_2^{M,N} \to N_2\),
%     \(g_1,\dots,g_M : N_2^{m,0} \to N_2\), and
%     \(h_1,\dots,h_N\) each consume disjoint subsets of safe inputs, then
%     \[
%       (f \circ \langle g_1,\dots,g_M : h_1,\dots,h_N\rangle)(x : y)
%       = f\big(g_1(x:),\dots,g_M(x:) : h_1(x:\mathbf{y}^{\,1}),\dots\big),
%     \]
%     where the tuple \(y\) is partitioned so that each safe variable appears in
%     at most one block \(\mathbf{y}^{\,j}\).
%   \item \textbf{Safe affine course-of-value recursion}:
%     given \(g : N_2^{m,n}\to N_2\),
%     \(h_0,h_1 : N_2^{m+1,1}\to N_2\),
%     \(d_0,d_1 : N_2^{m+1,0}\to N_2\),
%     define \(f = \mathrm{rec}(g,h_0,\delta_0,h_1,\delta_1)\) by
%     \[
%       f(n,x:y) =
%       \begin{cases}
%         g(x:y), & n=\varepsilon,\\[4pt]
%         h_{b_1}\big(b_k\cdots b_2, x : f(b_k\cdots b_2+\delta, x:y)\big),
%         & n = b_k\cdots b_2 b_1,
%       \end{cases}
%     \]
%     where \(\delta = \bigl|d_{b_1}(b_k\cdots b_2, x:)\bigr|\).
% \end{enumerate}
% Notation follows the original presentation: nullary \(f\) abbreviates
% \(f \circ \langle : \rangle\), and \(\mathrm{rec}(g,h,\delta)\) stands for
% \(\mathrm{rec}(g,h,\delta,h,\delta)\).

% \paragraph{Intuition.}
% Affine use of safe inputs prevents duplication and thus uncontrolled growth,
% while normal inputs control recursion depth.
% Safe affine composition confines normal arguments to depend only on normal data,
% and course-of-value recursion can inspect earlier values via the offset terms,
% yet the recursive result always flows back into a safe position linearly.
% Removing the affine restriction recovers the original Bellantoni--Cook algebra.

% - koncepcja: różnica między algebrą BCeps- a BC jest taka, że BCeps- "wymaga"
%   re-obliczania podwyrażeń po zrobieniu na nich ifa. To jest insight za L neq P
  

% in neergaard's logic for logspace, we cannot use the result of computation after doing an `if` on the result.
% this 'affinity' seems to be the difference between algebra for \complexity{FL} and for \complexity{FP}.

% but: we know a similar picture. in proof theory, we have dag-like and tree-like proof systems,
% and the difference between them is than in dag-like proof systems we can name a fragment of proof
% and then refer to the name in many places. and we have a lot of results about probably
% exponential difference of size of proofs of propositional tautologies in these two


% \section{Logspace-Oriented Developments}
% Lind developed early logspace-oriented function algebras in 1973 and
% 1974~\cite{10.1145/1008293.1008295,lind1974logspace}, relying on explicit
% resource bounds.
% Bellantoni and Cook also investigated unary encodings suitable for
% logspace functions with small outputs~\cite{10.1007/BF01201998},
% and Jones explored tail-recursive read-only programs~\cite{JONES1999151}.
% Murawski and Ong introduced \(BC^{-}\) in 2000~\cite{murawski2000can},
% with further refinements in 2004~\cite{MURAWSKI2004197}, and
% Møller-Neergaard proved \(BC\varepsilon^{-} = \complexity{FL}\) in the same
% period.
% Hofmann summarised logspace languages in 2006~\cite{hofmann2006logspace},
% and Schöpp traced the history of logspace characterisations~\cite{schoepp2006spaceefficiency}.

% The original \(BC\text{-}\varepsilon\) code has been ported from Moscow ML to
% SML/NJ and released under a compatible licence, alongside an unpublished note
% that clarifies the original presentation.\footnote{\url{https://github.com/ruplet/neergaard-logspace-characterization}}
% The accompanying Haskell formalisation reproduces key examples from
% Neergaard's paper; one correction shows that the published definition of
% \(\mathsf{shiftR}\) swaps its arguments.
% The proof of this fact appears in \texttt{thesis-tex/main.tex}.

% \begin{verbatim}
% identity :: Func
% identity = Proj 1 0 1

% oneNormalToZero :: Func
% oneNormalToZero =
%   let g = ZeroFunc in
%   let h = Proj 1 1 2 in
%   let d = identity in
%   Recursion 0 0 g h h d d

% -- Proposition 1. Let m and n be numbers in binary. Right shift shiftR(m : n)
% -- of m by |n| and selection of bit |n| from m are definable in BCe-.

% -- shiftR(n : m) = m >> |n|
% shiftR :: Func
% shiftR =
%   let g = Proj 0 1 1 in
%   let d = oneNormalToZero in
%   -- h(timer : recursive) = tail(recursive)
%   let h = Composition 0 1 1 [1] Tail [] [Proj 1 1 2] in
%   Recursion 0 1 g h h d d
% \end{verbatim}
